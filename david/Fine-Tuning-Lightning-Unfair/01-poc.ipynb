{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Your Custom AI/LLM With PyTorch Lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/arch.png\" alt=\"Cohere logo\" width=\"800\" height=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import TrainConfig\n",
    "import torch\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Free up gpu vRAM from memory leaks.\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = TrainConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda3/envs/r_unfair/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = train_config.pretrained_model\n",
    "num_classes = train_config.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'roberta-base'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=pretrained_model,\n",
    "    num_labels=num_classes,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PEFT (QLORA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_model, LoraConfig, TaskType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TaskType:\n",
    "\n",
    "Overview of the supported task types:\n",
    "- SEQ_CLS: Text classification.\n",
    "- SEQ_2_SEQ_LM: Sequence-to-sequence language modeling.\n",
    "- CAUSAL_LM: Causal language modeling.\n",
    "- TOKEN_CLS: Token classification.\n",
    "- QUESTION_ANS: Question answering.\n",
    "- FEATURE_EXTRACTION: Feature extraction. Provides the hidden states which can be used as embeddings or features\n",
    "  for downstream tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We are interested in **SEQ_CLS**\n",
    "- Set the `inference_mode` to False to enable these layers in training mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    inference_mode=False,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LoRA (Low-Rank Adaptation) is a technique for efficiently fine-tuning large language models by introducing low-rank matrices into the architecture. Here's the rigorous mathematical explanation of how the parameters `lora_alpha`, `r`, and `lora_dropout` are used in the LoRA framework:\n",
    "\n",
    "---\n",
    "\n",
    "### Core Idea Behind LoRA\n",
    "The key idea is to approximate the updates to a pretrained model's weight matrix $W \\in \\mathbb{R}^{d \\times k}$ with a low-rank decomposition:\n",
    "$$\n",
    "\\Delta W \\approx A B\n",
    "$$\n",
    "where:\n",
    "- $A \\in \\mathbb{R}^{d \\times r}$ and $B \\in \\mathbb{R}^{r \\times k}$ are low-rank matrices.\n",
    "- $r \\ll \\min(d, k)$, reducing the number of trainable parameters from $d \\times k$ to $r \\times (d + k)$.\n",
    "\n",
    "The LoRA weight update is incorporated into the model as:\n",
    "$$\n",
    "W_{\\text{effective}} = W + \\Delta W = W + A B\n",
    "$$\n",
    "Here, $W$ is the pretrained weight matrix, and $\\Delta W$ represents the learned low-rank update.\n",
    "\n",
    "---\n",
    "\n",
    "### LoRA Parameters in Detail\n",
    "\n",
    "#### 1. **`r` (Rank of Decomposition)**\n",
    "- **Definition**: $r$ is the rank of the low-rank decomposition.\n",
    "- **Mathematical Role**:\n",
    "  - Controls the dimensionality of the intermediate representation in the decomposition $\\Delta W = A B$.\n",
    "  - A larger $r$ allows more expressive updates, but increases the number of trainable parameters ($r \\times (d + k)$).\n",
    "- **Parameter Count**:\n",
    "  - Trainable parameters introduced by LoRA: $r \\times (d + k)$.\n",
    "- **Trade-off**:\n",
    "  - Low $r$: Less expressive, more efficient.\n",
    "  - High $r$: More expressive, less efficient.\n",
    "\n",
    "#### 2. **`lora_alpha` (Scaling Factor)**\n",
    "- **Definition**: A scalar $\\alpha$ that scales the output of the low-rank update.\n",
    "- **Mathematical Role**:\n",
    "  - Ensures numerical stability and controls the magnitude of the updates.\n",
    "  - The effective update becomes:\n",
    "    $$\n",
    "    \\Delta W = \\frac{\\alpha}{r} A B\n",
    "    $$\n",
    "  - Dividing $\\alpha$ by $r$ ensures the scale of the updates is independent of the rank $r$, preventing instability when $r$ is large.\n",
    "- **Intuition**:\n",
    "  - $\\alpha$ adjusts how much influence the low-rank adaptation has on the pretrained weights $W$.\n",
    "\n",
    "#### 3. **`lora_dropout` (Dropout for Regularization)**\n",
    "- **Definition**: Dropout applied to the low-rank matrix $A$ during training to regularize the adaptation.\n",
    "- **Mathematical Role**:\n",
    "  - During training, a dropout mask $M$ (where $M \\sim \\text{Bernoulli}(1-p)$) is applied to $A$:\n",
    "    $$\n",
    "    A' = M \\odot A\n",
    "    $$\n",
    "  - The modified low-rank update becomes:\n",
    "    $$\n",
    "    \\Delta W = \\frac{\\alpha}{r} A' B\n",
    "    $$\n",
    "  - This introduces sparsity in the updates during training, reducing overfitting.\n",
    "- **Trade-off**:\n",
    "  - Low dropout (small $p$): Less regularization, more prone to overfitting.\n",
    "  - High dropout (large $p$): Stronger regularization, potentially underfitting.\n",
    "\n",
    "---\n",
    "\n",
    "### Full Expression of LoRA Weight Update\n",
    "Incorporating all these components, the effective weight matrix during training is:\n",
    "$$\n",
    "W_{\\text{effective}} = W + \\Delta W = W + \\frac{\\alpha}{r} \\left( M \\odot A \\right) B\n",
    "$$\n",
    "where:\n",
    "- $W$: Pretrained weight matrix.\n",
    "- $A$ and $B$: Trainable low-rank matrices.\n",
    "- $r$: Rank of decomposition.\n",
    "- $\\alpha$: Scaling factor.\n",
    "- $M$: Dropout mask.\n",
    "\n",
    "---\n",
    "\n",
    "### Example Breakdown\n",
    "Given your configuration:\n",
    "- $r = 8$: Low-rank decomposition introduces $8$ dimensions for the intermediate representation.\n",
    "- $\\alpha = 32$: Updates are scaled by $\\frac{32}{8} = 4$ to adjust their magnitude.\n",
    "- $\\text{dropout} = 0.1$: A dropout probability of $0.1$ regularizes the updates.\n",
    "\n",
    "### Impact on Parameter Efficiency\n",
    "The number of trainable parameters added by LoRA is:\n",
    "$$\n",
    "\\text{Trainable Params} = r \\times (d + k)\n",
    "$$\n",
    "For example, if $d = 768$ and $k = 768$, and $r = 8$:\n",
    "$$\n",
    "\\text{Trainable Params} = 8 \\times (768 + 768) = 12,288\n",
    "$$\n",
    "This is significantly smaller than the $768 \\times 768 = 589,824$ parameters of the original weight matrix.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary\n",
    "- **`r`**: Controls the expressiveness of the low-rank decomposition.\n",
    "- **`alpha`**: Scales the low-rank updates for stability and proportionality.\n",
    "- **`dropout`**: Regularizes the updates to prevent overfitting.\n",
    "This formulation enables efficient fine-tuning of large models with minimal additional parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    inference_mode=False,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 887,042 || all params: 125,534,212 || trainable%: 0.7066\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Set the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0002"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = train_config.lr\n",
    "lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch Lightning: save_hyperparameters\n",
    "\n",
    "In PyTorch Lightning, the save_hyperparameters method is used to save the initialization arguments (hyperparameters) of a LightningModule. This allows the framework to store and later retrieve these hyperparameters for logging, checkpointing, and reproducibility purposes\n",
    "\n",
    "- When called, save_hyperparameters captures the arguments passed to the __init__ method of the LightningModule and saves them as part of the module's internal state.\n",
    "\n",
    "- The saved hyperparameters are included in the checkpoints automatically created by PyTorch Lightning during training. This ensures that if you reload a model from a checkpoint, the hyperparameters are restored.\n",
    "\n",
    "- Many logging frameworks, like TensorBoard, WandB, or MLFlow, can automatically log the hyperparameters saved using this method, enabling better experiment tracking.\n",
    "\n",
    "- After calling save_hyperparameters, the stored arguments are accessible through the self.hparams attribute, which acts like a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.save_hyperparameters(\"pretrained_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "def save_hyperparameters(*args, **kwargs):\n",
    "    # Combine positional arguments and keyword arguments into a Namespace\n",
    "    params = Namespace(**{key: val for key, val in kwargs.items()})\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta-base\n",
      "0.0002\n"
     ]
    }
   ],
   "source": [
    "# Save hyperparameters\n",
    "hparams = save_hyperparameters(pretrained_model=pretrained_model, num_classes=num_classes, lr=lr)\n",
    "\n",
    "# Access hyperparameters\n",
    "print(hparams.pretrained_model)  # Outputs: \"bert-base-uncased\"\n",
    "print(hparams.lr)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data (LexGlueDataModule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "import polars as pl\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from lightning import LightningDataModule\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = train_config.pretrained_model\n",
    "max_length = train_config.max_length\n",
    "batch_size = train_config.batch_size\n",
    "num_workers = train_config.num_workers\n",
    "debug_mode_sample = train_config.debug_mode_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained model: roberta-base\n",
      "Max length: 128\n",
      "Batch size: 256\n",
      "Number of workers: 32\n",
      "Debug mode sample: None\n"
     ]
    }
   ],
   "source": [
    "print(\"Pretrained model:\", pretrained_model)\n",
    "print(\"Max length:\", max_length)\n",
    "print(\"Batch size:\", batch_size)\n",
    "print(\"Number of workers:\", num_workers)\n",
    "print(\"Debug mode sample:\", debug_mode_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsname = \"lex_glue\"\n",
    "dsdict = DatasetDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaTokenizerFast(name_or_path='roberta-base', vocab_size=50265, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t50264: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', ',', 'Ġworld', '!']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[31414, 6, 8331, 328]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids([\"Hello\", \",\", \"world\", \"!\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/david/Documents/data_science/llm/david/Fine-Tuning-Lightning-Unfair\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda3/envs/r_unfair/lib/python3.10/pty.py:89: RuntimeWarning: Using fork() can cause Polars to deadlock in the child process.\n",
      "In addition, using fork() with Python in general is a recipe for mysterious\n",
      "deadlocks and crashes.\n",
      "\n",
      "The most likely reason you are seeing this error is because you are using the\n",
      "multiprocessing module on Linux, which uses fork() by default. This will be\n",
      "fixed in Python 3.14. Until then, you want to use the \"spawn\" context instead.\n",
      "\n",
      "See https://docs.pola.rs/user-guide/misc/multiprocessing/ for details.\n",
      "\n",
      "If you really know what your doing, you can silence this warning with the warning module\n",
      "or by setting POLARS_ALLOW_FORKING_THREAD=1.\n",
      "\n",
      "  pid, fd = os.forkpty()\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dsdict = load_dataset(dsname, \"unfair_tos\")\n",
    "# Split data into train, validation, and test\n",
    "dsdict[\"train\"] = load_dataset(dsname, \"unfair_tos\", split=\"train\")\n",
    "dsdict[\"validation\"] = load_dataset(dsname, \"unfair_tos\", split=\"validation\")\n",
    "dsdict[\"test\"] = load_dataset(dsname, \"unfair_tos\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 5532\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 2275\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 1607\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'labels'],\n",
       "    num_rows: 5532\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsdict[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5527</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5528</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5529</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5530</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5531</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5532 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1   2\n",
       "0     NaN  NaN NaN\n",
       "1     NaN  NaN NaN\n",
       "2     NaN  NaN NaN\n",
       "3     NaN  NaN NaN\n",
       "4     NaN  NaN NaN\n",
       "...   ...  ...  ..\n",
       "5527  NaN  NaN NaN\n",
       "5528  NaN  NaN NaN\n",
       "5529  5.0  6.0 NaN\n",
       "5530  NaN  NaN NaN\n",
       "5531  NaN  NaN NaN\n",
       "\n",
       "[5532 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels = pd.DataFrame(dsdict[\"train\"][\"labels\"])\n",
    "df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5512</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5513</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5516</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5517</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5529</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>630 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2\n",
       "8     4.0  NaN  NaN\n",
       "10    2.0  NaN  NaN\n",
       "12    2.0  NaN  NaN\n",
       "15    4.0  NaN  NaN\n",
       "33    3.0  2.0  1.0\n",
       "...   ...  ...  ...\n",
       "5512  0.0  NaN  NaN\n",
       "5513  0.0  NaN  NaN\n",
       "5516  1.0  NaN  NaN\n",
       "5517  1.0  NaN  NaN\n",
       "5529  5.0  6.0  NaN\n",
       "\n",
       "[630 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = df_labels[0].isna()\n",
    "df_labels[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'notice to california subscribers : you may cancel your subscription , without penalty or obligation , at any time prior to midnight of the third business day following the date you subscribed . \\n',\n",
       " 'labels': []}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsdict[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'if you subscribed using your apple id , refunds are handled by apple , not tinder . \\n',\n",
       " 'labels': []}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsdict[\"train\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': Value(dtype='string', id=None), 'labels': Sequence(feature=ClassLabel(names=['Limitation of liability', 'Unilateral termination', 'Unilateral change', 'Content removal', 'Contract by using', 'Choice of law', 'Jurisdiction', 'Arbitration'], id=None), length=-1, id=None)}\n"
     ]
    }
   ],
   "source": [
    "print(dsdict[\"train\"].features) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper functions\n",
    "def preprocess(batch: dict) -> dict:\n",
    "    \"\"\"Tokenize the text field and convert labels for binary classification.\"\"\"\n",
    "    tokens = tokenizer(\n",
    "        batch[\"text\"],\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "    )\n",
    "    tokens[\"label\"] = [1 if label else 0 for label in batch[\"labels\"]]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a batch\n",
    "sample_batch = {\n",
    "    \"text\": [\n",
    "        \"Tinder may terminate your account at any time without notice if it believes that you have violated this agreement.\",\n",
    "        \"Notice to California subscribers: you may cancel your subscription, without penalty or obligation, at any time prior to midnight of the third business day following the date you subscribed.\",\n",
    "    ],\n",
    "    \"labels\": [2, 0],  # Example labels\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define max_length and tokenizer for preprocessing\n",
    "max_length = 128\n",
    "pretrained_model = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the preprocess function on the simulated batch\n",
    "processed_batch = preprocess(sample_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 9543, 4063, 2089, 20320, 2115, 4070, 2012, 2151, 2051, 2302, 5060, 2065, 2009, 7164, 2008, 2017, 2031, 14424, 2023, 3820, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 5060, 2000, 2662, 17073, 1024, 2017, 2089, 17542, 2115, 15002, 1010, 2302, 6531, 2030, 14987, 1010, 2012, 2151, 2051, 3188, 2000, 7090, 1997, 1996, 2353, 2449, 2154, 2206, 1996, 3058, 2017, 4942, 29234, 2094, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'label': [1, 0]}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'label'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 128)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(processed_batch.attention_mask).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 128)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(processed_batch.input_ids).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  101,  9543,  4063,  2089, 20320,  2115,  4070,  2012,  2151,\n",
       "         2051,  2302,  5060,  2065,  2009,  7164,  2008,  2017,  2031,\n",
       "        14424,  2023,  3820,  1012,   102,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0],\n",
       "       [  101,  5060,  2000,  2662, 17073,  1024,  2017,  2089, 17542,\n",
       "         2115, 15002,  1010,  2302,  6531,  2030, 14987,  1010,  2012,\n",
       "         2151,  2051,  3188,  2000,  7090,  1997,  1996,  2353,  2449,\n",
       "         2154,  2206,  1996,  3058,  2017,  4942, 29234,  2094,  1012,\n",
       "          102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(processed_batch.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(processed_batch.attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(processed_batch.token_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(processed_batch.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### balance sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function balanced_sample is designed to create a balanced dataset from an imbalanced dataset by sampling an equal number of examples from each class (fair and unfair). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_sample(df: pl.DataFrame, sample_size: int, seed: int = 42) -> pl.DataFrame:\n",
    "    \"\"\"Balance the dataset by sampling an equal number of fair and unfair examples.\"\"\"\n",
    "    fairness = df[\"labels\"].apply(lambda x: min(len(x), 1))\n",
    "    fair = df.filter(fairness.eq(0)).sample(fairness.sum(), seed=seed)\n",
    "    unfair = df.filter(fairness.ne(0))\n",
    "    balanced = pl.concat([fair, unfair])\n",
    "    return balanced.sample(n=sample_size, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.17.1'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>notice to california subscribers : you may can...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>if you subscribed using your apple id , refund...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>if you wish to request a refund , please visit...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if you subscribed using your google play store...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>key changes in this version : we 've included ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>for a summary of our terms of use , go to summ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>welcome to tinder , operated by match group , ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>acceptance of terms of use agreement . \\n</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>by creating a tinder account or by using the t...</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>if you do not accept and agree to be bound by ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text labels\n",
       "0  notice to california subscribers : you may can...     []\n",
       "1  if you subscribed using your apple id , refund...     []\n",
       "2  if you wish to request a refund , please visit...     []\n",
       "3  if you subscribed using your google play store...     []\n",
       "4  key changes in this version : we 've included ...     []\n",
       "5  for a summary of our terms of use , go to summ...     []\n",
       "6  welcome to tinder , operated by match group , ...     []\n",
       "7          acceptance of terms of use agreement . \\n     []\n",
       "8  by creating a tinder account or by using the t...    [4]\n",
       "9  if you do not accept and agree to be bound by ...     []"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = \"train\"\n",
    "ds = dsdict[split]\n",
    "ds.data.to_pandas().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.from_arrow(ds.data.table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5_532, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>text</th><th>labels</th></tr><tr><td>str</td><td>list[i64]</td></tr></thead><tbody><tr><td>&quot;notice to california subscribe…</td><td>[]</td></tr><tr><td>&quot;if you subscribed using your a…</td><td>[]</td></tr><tr><td>&quot;if you wish to request a refun…</td><td>[]</td></tr><tr><td>&quot;if you subscribed using your g…</td><td>[]</td></tr><tr><td>&quot;key changes in this version : …</td><td>[]</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;any failure by us to enforce a…</td><td>[]</td></tr><tr><td>&quot;a person who is not a party to…</td><td>[]</td></tr><tr><td>&quot;irrespective of the country fr…</td><td>[5, 6]</td></tr><tr><td>&quot;if you require further informa…</td><td>[]</td></tr><tr><td>&quot;alternatively , you can write …</td><td>[]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5_532, 2)\n",
       "┌─────────────────────────────────┬───────────┐\n",
       "│ text                            ┆ labels    │\n",
       "│ ---                             ┆ ---       │\n",
       "│ str                             ┆ list[i64] │\n",
       "╞═════════════════════════════════╪═══════════╡\n",
       "│ notice to california subscribe… ┆ []        │\n",
       "│ if you subscribed using your a… ┆ []        │\n",
       "│ if you wish to request a refun… ┆ []        │\n",
       "│ if you subscribed using your g… ┆ []        │\n",
       "│ key changes in this version : … ┆ []        │\n",
       "│ …                               ┆ …         │\n",
       "│ any failure by us to enforce a… ┆ []        │\n",
       "│ a person who is not a party to… ┆ []        │\n",
       "│ irrespective of the country fr… ┆ [5, 6]    │\n",
       "│ if you require further informa… ┆ []        │\n",
       "│ alternatively , you can write … ┆ []        │\n",
       "└─────────────────────────────────┴───────────┘"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_mode_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polars.dataframe.frame.DataFrame"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.select(pl.col(\"labels\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the UDF\n",
    "# def min_length_one(label_list):\n",
    "#     return min(len(label_list), 1)\n",
    "\n",
    "# # Apply the UDF to the 'labels' column\n",
    "# df = df.with_columns(\n",
    "#     pl.col(\"labels\").map_elements(min_length_one, return_dtype=pl.Int64).alias(\"fairness\")\n",
    "# )\n",
    "# fairness = df[\"fairness\"]\n",
    "\n",
    "# seed = 42\n",
    "# fair = df.filter(fairness.eq(0)).sample(fairness.sum(), seed=seed)\n",
    "# unfair = df.filter(fairness.ne(0))\n",
    "# balanced = pl.concat([fair, unfair])\n",
    "# balanced.sample(n=sample_size, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_ds = ds.map(\n",
    "    preprocess,\n",
    "    batched=True,\n",
    "    batch_size=32,\n",
    "    load_from_cache_file=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'labels', 'input_ids', 'token_type_ids', 'attention_mask', 'label'],\n",
       "    num_rows: 5532\n",
       "})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  5060,  2000,  ...,     0,     0,     0],\n",
       "        [  101,  2065,  2017,  ...,     0,     0,     0],\n",
       "        [  101,  2065,  2017,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101, 20868,  6072,  ...,     0,     0,     0],\n",
       "        [  101,  2065,  2017,  ...,     0,     0,     0],\n",
       "        [  101, 14084,  1010,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5532, 128])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds[\"input_ids\"].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 1, 0, 0])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5_532, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>text</th><th>labels</th></tr><tr><td>str</td><td>list[i64]</td></tr></thead><tbody><tr><td>&quot;notice to california subscribe…</td><td>[]</td></tr><tr><td>&quot;if you subscribed using your a…</td><td>[]</td></tr><tr><td>&quot;if you wish to request a refun…</td><td>[]</td></tr><tr><td>&quot;if you subscribed using your g…</td><td>[]</td></tr><tr><td>&quot;key changes in this version : …</td><td>[]</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;any failure by us to enforce a…</td><td>[]</td></tr><tr><td>&quot;a person who is not a party to…</td><td>[]</td></tr><tr><td>&quot;irrespective of the country fr…</td><td>[5, 6]</td></tr><tr><td>&quot;if you require further informa…</td><td>[]</td></tr><tr><td>&quot;alternatively , you can write …</td><td>[]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5_532, 2)\n",
       "┌─────────────────────────────────┬───────────┐\n",
       "│ text                            ┆ labels    │\n",
       "│ ---                             ┆ ---       │\n",
       "│ str                             ┆ list[i64] │\n",
       "╞═════════════════════════════════╪═══════════╡\n",
       "│ notice to california subscribe… ┆ []        │\n",
       "│ if you subscribed using your a… ┆ []        │\n",
       "│ if you wish to request a refun… ┆ []        │\n",
       "│ if you subscribed using your g… ┆ []        │\n",
       "│ key changes in this version : … ┆ []        │\n",
       "│ …                               ┆ …         │\n",
       "│ any failure by us to enforce a… ┆ []        │\n",
       "│ a person who is not a party to… ┆ []        │\n",
       "│ irrespective of the country fr… ┆ [5, 6]    │\n",
       "│ if you require further informa… ┆ []        │\n",
       "│ alternatively , you can write … ┆ []        │\n",
       "└─────────────────────────────────┴───────────┘"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's implement the setup replica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(batch: dict) -> dict:\n",
    "    \"\"\"Tokenize the text field and convert labels for binary classification.\"\"\"\n",
    "    tokens = tokenizer(\n",
    "        batch[\"text\"],\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "    )\n",
    "    tokens[\"label\"] = [1 if label else 0 for label in batch[\"labels\"]]\n",
    "    return tokens\n",
    "\n",
    "# Preprocess dataset\n",
    "def shared_transform(split: str):\n",
    "    \"\"\"Tokenize and preprocess the dataset split.\"\"\"\n",
    "    ds = dsdict[split]\n",
    "    tokenized_ds = ds.map(\n",
    "        preprocess,\n",
    "        batched=True,\n",
    "        load_from_cache_file=True,\n",
    "    )\n",
    "    tokenized_ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "    return tokenized_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare tokenized datasets\n",
    "train_dataset = shared_transform(\"train\")\n",
    "val_dataset = shared_transform(\"validation\")\n",
    "test_dataset = shared_transform(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 128]) torch.Size([256, 128]) torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "for batch in train_dataloader:\n",
    "    input_ids = batch[\"input_ids\"]\n",
    "    attention_mask = batch[\"attention_mask\"]\n",
    "    labels = batch[\"label\"]\n",
    "    print(input_ids.shape, attention_mask.shape, labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  3531,  2022,  ...,     0,     0,     0],\n",
       "        [  101,  2065,  2017,  ...,     0,     0,     0],\n",
       "        [  101,  2017,  5993,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  2065,  2017,  ...,     0,     0,     0],\n",
       "        [  101,  2224,  2151,  ...,     0,     0,     0],\n",
       "        [  101, 19575,  1010,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the model with the highest F1 score.\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filename=\"{epoch}-{Val_F1_Score:.2f}\",\n",
    "    monitor=\"Val_F1_Score\",\n",
    "    mode=\"max\",\n",
    "    verbose=True,\n",
    "    save_top_k=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping = EarlyStopping(\n",
    "    monitor=\"Val_F1_Score\",\n",
    "    min_delta=train_config.min_delta,\n",
    "    patience=train_config.patience,\n",
    "    verbose=True,\n",
    "    mode=\"max\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_config.min_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_config.patience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_callbacks = [earlystopping, checkpoint_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks import Callback as Cb\n",
    "for callback in l_callbacks:\n",
    "    assert isinstance(callback, Cb), f\"{callback} is not a valid Callback\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning import Trainer\n",
    "import logging\n",
    "from lightning.pytorch.loggers import CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a standard Python logger\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\"training_logger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logger = CSVLogger(save_dir=train_config.model_checkpoint_dir, name=\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "10\n",
      "/home/david/Documents/data_science/llm/david/model-checkpoints\n",
      "{'hours': 3}\n"
     ]
    }
   ],
   "source": [
    "print(bool(train_config.debug_mode_sample))\n",
    "print(train_config.max_epochs)\n",
    "print(train_config.model_checkpoint_dir)\n",
    "print(train_config.max_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    callbacks=l_callbacks,\n",
    "    default_root_dir=train_config.model_checkpoint_dir,\n",
    "    fast_dev_run=bool(train_config.debug_mode_sample),\n",
    "    max_epochs=train_config.max_epochs,\n",
    "    max_time=train_config.max_time,\n",
    "    precision=\"bf16-mixed\" if torch.cuda.is_available() else \"32-true\",\n",
    "    logger=csv_logger,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import LexGlueDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = LexGlueDataModule(\n",
    "    pretrained_model=train_config.pretrained_model,\n",
    "    max_length=train_config.max_length,\n",
    "    batch_size=train_config.batch_size,\n",
    "    num_workers=train_config.num_workers,\n",
    "    debug_mode_sample=train_config.debug_mode_sample,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 128]) torch.Size([256, 128]) torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "for batch in train_dataloader:\n",
    "    input_ids = batch[\"input_ids\"]\n",
    "    attention_mask = batch[\"attention_mask\"]\n",
    "    labels = batch[\"label\"]\n",
    "    print(input_ids.shape, attention_mask.shape, labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2065,  2017,  ...,     0,     0,     0],\n",
       "         [  101,  2057,  2467,  ...,     0,     0,     0],\n",
       "         [  101,  2324,  1012,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [  101,  2004,  1037,  ...,     0,     0,     0],\n",
       "         [  101,  2017, 13399,  ...,     0,     0,     0],\n",
       "         [  101,  7858,  2038,  ...,     0,     0,     0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'label': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "         0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0])}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "classif_out = model(\n",
    "    input_ids=batch[\"input_ids\"],\n",
    "    attention_mask=batch[\"attention_mask\"],\n",
    "    labels=batch[\"label\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['loss', 'logits'])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classif_out.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6561, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classif_out.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default Hugging Face uses:\n",
    "-  Negative Log-Likelihood Loss (NLLLoss).\n",
    "\n",
    "$$\\text{loss} = - \\frac{1}{N} \\sum_{i=1}^N \\log(\\text{probability of the correct class for } i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "loss = loss_fn(classif_out.logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 2])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classif_out.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6561, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from architectures import TransformerModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 887,042 || all params: 125,534,212 || trainable%: 0.7066\n"
     ]
    }
   ],
   "source": [
    "model = TransformerModule(\n",
    "    pretrained_model=train_config.pretrained_model,\n",
    "    num_classes=train_config.num_classes,\n",
    "    lr=train_config.lr,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                               | Params | Mode \n",
      "---------------------------------------------------------------------\n",
      "0 | model | PeftModelForSequenceClassification | 125 M  | train\n",
      "---------------------------------------------------------------------\n",
      "887 K     Trainable params\n",
      "124 M     Non-trainable params\n",
      "125 M     Total params\n",
      "502.137   Total estimated model params size (MB)\n",
      "244       Modules in train mode\n",
      "234       Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2275/2275 [00:00<00:00, 16724.46 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5532/5532 [00:01<00:00, 3929.34 examples/s]\n",
      "/home/david/anaconda3/envs/r_unfair/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (21) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 21/21 [00:04<00:00,  4.85it/s, v_num=0]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# trainer.fit(model=model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: embeddings.word_embeddings.weight | Status: Frozen | Shape: torch.Size([50265, 768])\n",
      "Layer: embeddings.position_embeddings.weight | Status: Frozen | Shape: torch.Size([514, 768])\n",
      "Layer: embeddings.token_type_embeddings.weight | Status: Frozen | Shape: torch.Size([1, 768])\n",
      "Layer: embeddings.LayerNorm.weight | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: embeddings.LayerNorm.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.0.attention.self.query.base_layer.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.0.attention.self.query.base_layer.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.0.attention.self.query.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.0.attention.self.query.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.0.attention.self.key.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.0.attention.self.key.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.0.attention.self.value.base_layer.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.0.attention.self.value.base_layer.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.0.attention.self.value.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.0.attention.self.value.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.0.attention.output.dense.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.0.attention.output.dense.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.0.attention.output.LayerNorm.weight | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.0.attention.output.LayerNorm.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.0.intermediate.dense.weight | Status: Frozen | Shape: torch.Size([3072, 768])\n",
      "Layer: encoder.layer.0.intermediate.dense.bias | Status: Frozen | Shape: torch.Size([3072])\n",
      "Layer: encoder.layer.0.output.dense.weight | Status: Frozen | Shape: torch.Size([768, 3072])\n",
      "Layer: encoder.layer.0.output.dense.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.0.output.LayerNorm.weight | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.0.output.LayerNorm.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.1.attention.self.query.base_layer.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.1.attention.self.query.base_layer.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.1.attention.self.query.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.1.attention.self.query.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.1.attention.self.key.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.1.attention.self.key.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.1.attention.self.value.base_layer.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.1.attention.self.value.base_layer.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.1.attention.self.value.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.1.attention.self.value.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.1.attention.output.dense.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.1.attention.output.dense.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.1.attention.output.LayerNorm.weight | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.1.attention.output.LayerNorm.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.1.intermediate.dense.weight | Status: Frozen | Shape: torch.Size([3072, 768])\n",
      "Layer: encoder.layer.1.intermediate.dense.bias | Status: Frozen | Shape: torch.Size([3072])\n",
      "Layer: encoder.layer.1.output.dense.weight | Status: Frozen | Shape: torch.Size([768, 3072])\n",
      "Layer: encoder.layer.1.output.dense.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.1.output.LayerNorm.weight | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.1.output.LayerNorm.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.2.attention.self.query.base_layer.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.2.attention.self.query.base_layer.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.2.attention.self.query.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.2.attention.self.query.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.2.attention.self.key.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.2.attention.self.key.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.2.attention.self.value.base_layer.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.2.attention.self.value.base_layer.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.2.attention.self.value.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.2.attention.self.value.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.2.attention.output.dense.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.2.attention.output.dense.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.2.attention.output.LayerNorm.weight | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.2.attention.output.LayerNorm.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.2.intermediate.dense.weight | Status: Frozen | Shape: torch.Size([3072, 768])\n",
      "Layer: encoder.layer.2.intermediate.dense.bias | Status: Frozen | Shape: torch.Size([3072])\n",
      "Layer: encoder.layer.2.output.dense.weight | Status: Frozen | Shape: torch.Size([768, 3072])\n",
      "Layer: encoder.layer.2.output.dense.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.2.output.LayerNorm.weight | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.2.output.LayerNorm.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.3.attention.self.query.base_layer.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.3.attention.self.query.base_layer.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.3.attention.self.query.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.3.attention.self.query.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.3.attention.self.key.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.3.attention.self.key.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.3.attention.self.value.base_layer.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.3.attention.self.value.base_layer.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.3.attention.self.value.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.3.attention.self.value.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.3.attention.output.dense.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.3.attention.output.dense.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.3.attention.output.LayerNorm.weight | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.3.attention.output.LayerNorm.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.3.intermediate.dense.weight | Status: Frozen | Shape: torch.Size([3072, 768])\n",
      "Layer: encoder.layer.3.intermediate.dense.bias | Status: Frozen | Shape: torch.Size([3072])\n",
      "Layer: encoder.layer.3.output.dense.weight | Status: Frozen | Shape: torch.Size([768, 3072])\n",
      "Layer: encoder.layer.3.output.dense.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.3.output.LayerNorm.weight | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.3.output.LayerNorm.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.4.attention.self.query.base_layer.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.4.attention.self.query.base_layer.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.4.attention.self.query.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.4.attention.self.query.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.4.attention.self.key.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.4.attention.self.key.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.4.attention.self.value.base_layer.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.4.attention.self.value.base_layer.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.4.attention.self.value.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.4.attention.self.value.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.4.attention.output.dense.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.4.attention.output.dense.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.4.attention.output.LayerNorm.weight | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.4.attention.output.LayerNorm.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.4.intermediate.dense.weight | Status: Frozen | Shape: torch.Size([3072, 768])\n",
      "Layer: encoder.layer.4.intermediate.dense.bias | Status: Frozen | Shape: torch.Size([3072])\n",
      "Layer: encoder.layer.4.output.dense.weight | Status: Frozen | Shape: torch.Size([768, 3072])\n",
      "Layer: encoder.layer.4.output.dense.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.4.output.LayerNorm.weight | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.4.output.LayerNorm.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.5.attention.self.query.base_layer.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.5.attention.self.query.base_layer.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.5.attention.self.query.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.5.attention.self.query.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.5.attention.self.key.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.5.attention.self.key.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.5.attention.self.value.base_layer.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.5.attention.self.value.base_layer.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.5.attention.self.value.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.5.attention.self.value.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.5.attention.output.dense.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.5.attention.output.dense.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.5.attention.output.LayerNorm.weight | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.5.attention.output.LayerNorm.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.5.intermediate.dense.weight | Status: Frozen | Shape: torch.Size([3072, 768])\n",
      "Layer: encoder.layer.5.intermediate.dense.bias | Status: Frozen | Shape: torch.Size([3072])\n",
      "Layer: encoder.layer.5.output.dense.weight | Status: Frozen | Shape: torch.Size([768, 3072])\n",
      "Layer: encoder.layer.5.output.dense.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.5.output.LayerNorm.weight | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.5.output.LayerNorm.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.6.attention.self.query.base_layer.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.6.attention.self.query.base_layer.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.6.attention.self.query.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.6.attention.self.query.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.6.attention.self.key.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.6.attention.self.key.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.6.attention.self.value.base_layer.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.6.attention.self.value.base_layer.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.6.attention.self.value.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.6.attention.self.value.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.6.attention.output.dense.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.6.attention.output.dense.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.6.attention.output.LayerNorm.weight | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.6.attention.output.LayerNorm.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.6.intermediate.dense.weight | Status: Frozen | Shape: torch.Size([3072, 768])\n",
      "Layer: encoder.layer.6.intermediate.dense.bias | Status: Frozen | Shape: torch.Size([3072])\n",
      "Layer: encoder.layer.6.output.dense.weight | Status: Frozen | Shape: torch.Size([768, 3072])\n",
      "Layer: encoder.layer.6.output.dense.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.6.output.LayerNorm.weight | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.6.output.LayerNorm.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.7.attention.self.query.base_layer.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.7.attention.self.query.base_layer.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.7.attention.self.query.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.7.attention.self.query.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.7.attention.self.key.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.7.attention.self.key.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.7.attention.self.value.base_layer.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.7.attention.self.value.base_layer.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.7.attention.self.value.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.7.attention.self.value.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.7.attention.output.dense.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.7.attention.output.dense.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.7.attention.output.LayerNorm.weight | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.7.attention.output.LayerNorm.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.7.intermediate.dense.weight | Status: Frozen | Shape: torch.Size([3072, 768])\n",
      "Layer: encoder.layer.7.intermediate.dense.bias | Status: Frozen | Shape: torch.Size([3072])\n",
      "Layer: encoder.layer.7.output.dense.weight | Status: Frozen | Shape: torch.Size([768, 3072])\n",
      "Layer: encoder.layer.7.output.dense.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.7.output.LayerNorm.weight | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.7.output.LayerNorm.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.8.attention.self.query.base_layer.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.8.attention.self.query.base_layer.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.8.attention.self.query.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.8.attention.self.query.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.8.attention.self.key.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.8.attention.self.key.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.8.attention.self.value.base_layer.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.8.attention.self.value.base_layer.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.8.attention.self.value.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.8.attention.self.value.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.8.attention.output.dense.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.8.attention.output.dense.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.8.attention.output.LayerNorm.weight | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.8.attention.output.LayerNorm.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.8.intermediate.dense.weight | Status: Frozen | Shape: torch.Size([3072, 768])\n",
      "Layer: encoder.layer.8.intermediate.dense.bias | Status: Frozen | Shape: torch.Size([3072])\n",
      "Layer: encoder.layer.8.output.dense.weight | Status: Frozen | Shape: torch.Size([768, 3072])\n",
      "Layer: encoder.layer.8.output.dense.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.8.output.LayerNorm.weight | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.8.output.LayerNorm.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.9.attention.self.query.base_layer.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.9.attention.self.query.base_layer.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.9.attention.self.query.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.9.attention.self.query.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.9.attention.self.key.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.9.attention.self.key.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.9.attention.self.value.base_layer.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.9.attention.self.value.base_layer.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.9.attention.self.value.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.9.attention.self.value.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.9.attention.output.dense.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.9.attention.output.dense.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.9.attention.output.LayerNorm.weight | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.9.attention.output.LayerNorm.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.9.intermediate.dense.weight | Status: Frozen | Shape: torch.Size([3072, 768])\n",
      "Layer: encoder.layer.9.intermediate.dense.bias | Status: Frozen | Shape: torch.Size([3072])\n",
      "Layer: encoder.layer.9.output.dense.weight | Status: Frozen | Shape: torch.Size([768, 3072])\n",
      "Layer: encoder.layer.9.output.dense.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.9.output.LayerNorm.weight | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.9.output.LayerNorm.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.10.attention.self.query.base_layer.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.10.attention.self.query.base_layer.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.10.attention.self.query.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.10.attention.self.query.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.10.attention.self.key.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.10.attention.self.key.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.10.attention.self.value.base_layer.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.10.attention.self.value.base_layer.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.10.attention.self.value.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.10.attention.self.value.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.10.attention.output.dense.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.10.attention.output.dense.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.10.attention.output.LayerNorm.weight | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.10.attention.output.LayerNorm.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.10.intermediate.dense.weight | Status: Frozen | Shape: torch.Size([3072, 768])\n",
      "Layer: encoder.layer.10.intermediate.dense.bias | Status: Frozen | Shape: torch.Size([3072])\n",
      "Layer: encoder.layer.10.output.dense.weight | Status: Frozen | Shape: torch.Size([768, 3072])\n",
      "Layer: encoder.layer.10.output.dense.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.10.output.LayerNorm.weight | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.10.output.LayerNorm.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.11.attention.self.query.base_layer.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.11.attention.self.query.base_layer.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.11.attention.self.query.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.11.attention.self.query.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.11.attention.self.key.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.11.attention.self.key.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.11.attention.self.value.base_layer.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.11.attention.self.value.base_layer.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.11.attention.self.value.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.11.attention.self.value.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.11.attention.output.dense.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: encoder.layer.11.attention.output.dense.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.11.attention.output.LayerNorm.weight | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.11.attention.output.LayerNorm.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.11.intermediate.dense.weight | Status: Frozen | Shape: torch.Size([3072, 768])\n",
      "Layer: encoder.layer.11.intermediate.dense.bias | Status: Frozen | Shape: torch.Size([3072])\n",
      "Layer: encoder.layer.11.output.dense.weight | Status: Frozen | Shape: torch.Size([768, 3072])\n",
      "Layer: encoder.layer.11.output.dense.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.11.output.LayerNorm.weight | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: encoder.layer.11.output.LayerNorm.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: model.base_model.model.classifier.original_module.dense.weight | Status: Frozen | Shape: torch.Size([768, 768])\n",
      "Layer: model.base_model.model.classifier.original_module.dense.bias | Status: Frozen | Shape: torch.Size([768])\n",
      "Layer: model.base_model.model.classifier.original_module.out_proj.weight | Status: Frozen | Shape: torch.Size([2, 768])\n",
      "Layer: model.base_model.model.classifier.original_module.out_proj.bias | Status: Frozen | Shape: torch.Size([2])\n",
      "Layer: model.base_model.model.classifier.modules_to_save.default.dense.weight | Status: Trainable | Shape: torch.Size([768, 768])\n",
      "Layer: model.base_model.model.classifier.modules_to_save.default.dense.bias | Status: Trainable | Shape: torch.Size([768])\n",
      "Layer: model.base_model.model.classifier.modules_to_save.default.out_proj.weight | Status: Trainable | Shape: torch.Size([2, 768])\n",
      "Layer: model.base_model.model.classifier.modules_to_save.default.out_proj.bias | Status: Trainable | Shape: torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "# All Layers\n",
    "for name, param in model.named_parameters():\n",
    "    trainable_status = \"Trainable\" if param.requires_grad else \"Frozen\"\n",
    "    # Delete the prefix in name \" model.base_model.model.roberta\":\n",
    "    if \"roberta\" in name:\n",
    "        name = name.split(\"model.base_model.model.roberta.\")[1]\n",
    "    print(f\"Layer: {name} | Status: {trainable_status} | Shape: {param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: encoder.layer.0.attention.self.query.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.0.attention.self.query.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.0.attention.self.value.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.0.attention.self.value.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.1.attention.self.query.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.1.attention.self.query.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.1.attention.self.value.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.1.attention.self.value.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.2.attention.self.query.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.2.attention.self.query.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.2.attention.self.value.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.2.attention.self.value.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.3.attention.self.query.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.3.attention.self.query.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.3.attention.self.value.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.3.attention.self.value.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.4.attention.self.query.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.4.attention.self.query.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.4.attention.self.value.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.4.attention.self.value.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.5.attention.self.query.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.5.attention.self.query.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.5.attention.self.value.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.5.attention.self.value.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.6.attention.self.query.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.6.attention.self.query.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.6.attention.self.value.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.6.attention.self.value.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.7.attention.self.query.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.7.attention.self.query.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.7.attention.self.value.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.7.attention.self.value.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.8.attention.self.query.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.8.attention.self.query.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.8.attention.self.value.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.8.attention.self.value.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.9.attention.self.query.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.9.attention.self.query.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.9.attention.self.value.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.9.attention.self.value.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.10.attention.self.query.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.10.attention.self.query.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.10.attention.self.value.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.10.attention.self.value.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.11.attention.self.query.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.11.attention.self.query.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: encoder.layer.11.attention.self.value.lora_A.default.weight | Status: Trainable | Shape: torch.Size([8, 768])\n",
      "Layer: encoder.layer.11.attention.self.value.lora_B.default.weight | Status: Trainable | Shape: torch.Size([768, 8])\n",
      "Layer: model.base_model.model.classifier.modules_to_save.default.dense.weight | Status: Trainable | Shape: torch.Size([768, 768])\n",
      "Layer: model.base_model.model.classifier.modules_to_save.default.dense.bias | Status: Trainable | Shape: torch.Size([768])\n",
      "Layer: model.base_model.model.classifier.modules_to_save.default.out_proj.weight | Status: Trainable | Shape: torch.Size([2, 768])\n",
      "Layer: model.base_model.model.classifier.modules_to_save.default.out_proj.bias | Status: Trainable | Shape: torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "# Only trainable\n",
    "for name, param in model.named_parameters():\n",
    "    trainable_status = \"Trainable\" if param.requires_grad else \"Frozen\"\n",
    "    # Delete the prefix in name \" model.base_model.model.roberta\":\n",
    "    if \"roberta\" in name:\n",
    "        name = name.split(\"model.base_model.model.roberta.\")[1]\n",
    "    if trainable_status == \"Trainable\":\n",
    "        print(f\"Layer: {name} | Status: {trainable_status} | Shape: {param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kr_unfair",
   "language": "python",
   "name": "kr_unfair"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
