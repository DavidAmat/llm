{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install accelerate==0.34.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers==4.45.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentence-transformers==3.1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 10. Creating Text Embedding Models\n",
    "\n",
    "## Contrastive Learning\n",
    "\n",
    "There are many ways we can apply contrastive learning to create text embedding models but the most well-known technique and framework is sentence-transformers.\n",
    "\n",
    "### SBERT\n",
    "\n",
    "Its approach fixes a major problem with the original BERT implementation for creating sentence embeddings, namely its computational overhead. \n",
    "\n",
    "Before sentence-transformers, sentence embeddings often used an architectural structure called **cross-encoders with BERT**.\n",
    "\n",
    "A cross-encoder allows two sentences to be passed to the Transformer network simultaneously to predict the extent to which the two sentences are similar. \n",
    "\n",
    "- by adding a classification head to the original architecture that can output a similarity score.\n",
    "- PROBLEM: the number of computations rises quickly when you want to find the highest pair in a collection of 10,000 sentences.\n",
    "- Moreover, a cross-encoder generally does not generate embeddings, it outputs a similarity score between the input sentences.\n",
    "\n",
    "\n",
    "A solution to this overhead is to generate embeddings from a BERT model by averaging its output layer or using the [CLS] token. This, however, has shown to be worse than simply averaging word vectors, like GloVe\n",
    "\n",
    "# <img src=\"imgs/crossencoder.png\" alt=\"Patching\" width=\"500\" height=\"200\">\n",
    "\n",
    "Instead, the authors of sentence-transformers approached the problem differently and searched for a method that is fast and creates embeddings that can be compared semantically. \n",
    "\n",
    "Unlike a cross-encoder, in **sentence-transformers** the **classification head is dropped**, and **mean pooling** is used on the final output layer to generate an embedding. \n",
    "\n",
    "- This pooling layer averages the word embeddings and gives back a fixed dimensional output vector. This ensures a fixed-size embedding.\n",
    "\n",
    "\n",
    "See the architecture of the original sentence-transformers model, which leverages a Siamese network, also called a **bi-encoder**.\n",
    "\n",
    "# <img src=\"imgs/biencoder.png\" alt=\"Patching\" width=\"350\" height=\"250\">\n",
    "\n",
    "The optimization process of these pairs of sentences is done through loss functions, which can have a major impact on the model’s performance. \n",
    "\n",
    "During training, the embeddings for each sentence are concatenated together with the difference between the embeddings. Then, this resulting embedding is optimized through a softmax classifier.\n",
    "\n",
    "**The resulting architecture is also referred to as a bi-encoder or SBERT for sentence-BERT**\n",
    "\n",
    "*Note: Although a bi-encoder is quite fast and creates accurate sentence representations, cross-encoders generally achieve better performance than a bi-encoder but do not generate embeddings.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform contrastive learning, we need two things. First, we need data that constitutes similar/dissimilar pairs. Second, we will need to define how the model defines and optimizes similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an Embedding Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Contrastive Examples\n",
    "\n",
    "When pretraining your embedding model, you will often see data being used from natural language inference (NLI) datasets:\n",
    "\n",
    "- NLI refers to the task of investigating whether, for a given premise, it entails the hypothesis (entailment), contradicts it (contradiction), or neither (neutral).\n",
    "\n",
    "The data that we are going to be using throughout creating and fine-tuning embedding models is derived from the **General Language Understanding Evaluation benchmark (GLUE)**. This GLUE benchmark consists of nine language understanding tasks to evaluate and analyze model performance.\n",
    "\n",
    "One of these tasks is the **Multi-Genre Natural Language Inference (MNLI)** corpus:\n",
    "- 392,702 sentence pairs\n",
    "- annotated with entailment (contradiction, neutral, entailment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, losses, models\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n",
    "from sentence_transformers.trainer import SentenceTransformerTrainer\n",
    "from sentence_transformers import InputExample\n",
    "from sentence_transformers.datasets import NoDuplicatesDataLoader\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "from sentence_transformers.datasets import DenoisingAutoEncoderDataset\n",
    "from mteb import MTEB\n",
    "import nltk\n",
    "import gc\n",
    "import torch\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNLI dataset from GLUE\n",
    "# 0 = entailment, 1 = neutral, 2 = contradiction\n",
    "train_dataset = load_dataset(\"glue\", \"mnli\", split=\"train\").select(range(50_000))\n",
    "train_dataset = train_dataset.remove_columns(\"idx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'premise': 'One of our number will carry out your instructions minutely.',\n",
       " 'hypothesis': 'A member of my team will execute your orders with immense precision.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'premise': \"yeah i tell you what though if you go price some of those tennis shoes i can see why now you know they're getting up in the hundred dollar range\",\n",
       " 'hypothesis': 'The tennis shoes have a range of prices.',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'premise': 'Gays and lesbians.', 'hypothesis': 'Heterosexuals.', 'label': 2}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model\n",
    "\n",
    "We typically choose an existing sentence-transformers model and fine-tune that model\n",
    "\n",
    "but in this example, **we are going to train an embedding from scratch**.\n",
    "\n",
    "We need to define 2 things:\n",
    "\n",
    "- a pretrained Transformer model that serves as embedding individual words\n",
    "-  define a loss function over which we will optimize the model (softmax loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name bert-base-uncased. Creating a new one with mean pooling.\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "embedding_model = SentenceTransformer('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function. In softmax loss, we will also need to explicitly set the number of labels.\n",
    "train_loss = losses.SoftmaxLoss(\n",
    "    model=embedding_model,\n",
    "    sentence_embedding_dimension=embedding_model.get_sentence_embedding_dimension(),\n",
    "    num_labels=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.get_sentence_embedding_dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(train_dataset[\"label\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we train our model, we define an evaluator to evaluate the model’s performance during training, which also determines the best model to save.\n",
    "\n",
    "We can perform evaluation of the performance of our model using the Semantic Textual Similarity Benchmark (STSB). It is a collection of human-labeled sentence pairs, with similarity scores between 1 and 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an embedding similarity evaluator for stsb\n",
    "val_sts = load_dataset('glue', 'stsb', split='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "    num_rows: 1500\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_sts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.0,\n",
       " 4.75,\n",
       " 5.0,\n",
       " 2.4000000953674316,\n",
       " 2.75,\n",
       " 2.615000009536743,\n",
       " 5.0,\n",
       " 2.3329999446868896,\n",
       " 3.75,\n",
       " 5.0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_sts[\"label\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A man with a hard hat is dancing.',\n",
       " 'A young child is riding a horse.',\n",
       " 'A man is feeding a mouse to a snake.',\n",
       " 'A woman is playing the guitar.',\n",
       " 'A woman is playing the flute.',\n",
       " 'A woman is cutting an onion.',\n",
       " 'A man is erasing a chalk board.',\n",
       " 'A woman is carrying a boy.',\n",
       " 'Three men are playing guitars.',\n",
       " 'A woman peels a potato.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_sts[\"sentence1\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A man wearing a hard hat is dancing.',\n",
       " 'A child is riding a horse.',\n",
       " 'The man is feeding a mouse to the snake.',\n",
       " 'A man is playing guitar.',\n",
       " 'A man is playing a flute.',\n",
       " 'A man is cutting onions.',\n",
       " 'The man is erasing the chalk board.',\n",
       " 'A woman is carrying her baby.',\n",
       " 'Three men are on stage playing guitars.',\n",
       " 'A woman is peeling a potato.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_sts[\"sentence2\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=val_sts[\"sentence1\"],\n",
    "    sentences2=val_sts[\"sentence2\"],\n",
    "    scores=[score/5 for score in val_sts[\"label\"]],\n",
    "    main_similarity=\"cosine\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Paramters to highlight:\n",
    "    - warmup_steps: the number of steps during which the learning rate will be linearly increased from zero to the initial learning rate defined for the training process. Note that we did not specify a custom learning rate for this training process.\n",
    "    - fp16: By enabling this parameter we allow for mixed precision training, where computations are performed using 16-bit floating-point numbers (FP16) instead of the default 32-bit (FP32). This reduces memory usage and potentially increases the training speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training arguments\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"training_base_embedding_model\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=100,\n",
    "    fp16=True,\n",
    "    eval_steps=100,\n",
    "    logging_steps=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train embedding model\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=embedding_model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    loss=train_loss,\n",
    "    evaluator=evaluator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdd12eea2ec348fd98a838a8ce26c40a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sentence_transformers.data_collator:Column 'hypothesis' is at index 1, whereas a column with this name is usually expected at index 0. Note that the column order can be important for some losses, e.g. MultipleNegativesRankingLoss will always consider the first column as the anchor and the second as the positive, regardless of the dataset column names. Consider renaming the columns to match the expected order, e.g.:\n",
      "dataset = dataset.select_columns(['hypothesis', 'entailment', 'contradiction'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0764, 'grad_norm': 2.6743345260620117, 'learning_rate': 5e-05, 'epoch': 0.06}\n",
      "{'loss': 0.9465, 'grad_norm': 2.88771653175354, 'learning_rate': 4.6582365003417636e-05, 'epoch': 0.13}\n",
      "{'loss': 0.8812, 'grad_norm': 3.460381507873535, 'learning_rate': 4.316473000683528e-05, 'epoch': 0.19}\n",
      "{'loss': 0.8422, 'grad_norm': 3.8805480003356934, 'learning_rate': 3.9747095010252904e-05, 'epoch': 0.26}\n",
      "{'loss': 0.8262, 'grad_norm': 4.558804512023926, 'learning_rate': 3.632946001367054e-05, 'epoch': 0.32}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbbf43d8f75042d6bf5bfe8df98dba90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8235, 'grad_norm': 3.3562326431274414, 'learning_rate': 3.291182501708818e-05, 'epoch': 0.38}\n",
      "{'loss': 0.8069, 'grad_norm': 4.393437385559082, 'learning_rate': 2.9494190020505813e-05, 'epoch': 0.45}\n",
      "{'loss': 0.7899, 'grad_norm': 4.835585594177246, 'learning_rate': 2.611073137388927e-05, 'epoch': 0.51}\n",
      "{'loss': 0.778, 'grad_norm': 4.837282657623291, 'learning_rate': 2.2693096377306907e-05, 'epoch': 0.58}\n",
      "{'loss': 0.7632, 'grad_norm': 4.742218494415283, 'learning_rate': 1.9275461380724537e-05, 'epoch': 0.64}\n",
      "{'loss': 0.7486, 'grad_norm': 3.6050546169281006, 'learning_rate': 1.5857826384142175e-05, 'epoch': 0.7}\n",
      "{'loss': 0.7292, 'grad_norm': 4.809312343597412, 'learning_rate': 1.2440191387559808e-05, 'epoch': 0.77}\n",
      "{'loss': 0.7467, 'grad_norm': 4.783884525299072, 'learning_rate': 9.022556390977444e-06, 'epoch': 0.83}\n",
      "{'loss': 0.7127, 'grad_norm': 3.5038461685180664, 'learning_rate': 5.604921394395079e-06, 'epoch': 0.9}\n",
      "{'loss': 0.7478, 'grad_norm': 5.3534698486328125, 'learning_rate': 2.187286397812714e-06, 'epoch': 0.96}\n",
      "{'train_runtime': 75.6031, 'train_samples_per_second': 661.349, 'train_steps_per_second': 20.674, 'train_loss': 0.8112286099698096, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1563, training_loss=0.8112286099698096, metrics={'train_runtime': 75.6031, 'train_samples_per_second': 661.349, 'train_steps_per_second': 20.674, 'total_flos': 0.0, 'train_loss': 0.8112286099698096, 'epoch': 1.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pearson_cosine': 0.5328487247553961,\n",
       " 'spearman_cosine': 0.610085819603248,\n",
       " 'pearson_manhattan': 0.595494529766493,\n",
       " 'spearman_manhattan': 0.6172999437988739,\n",
       " 'pearson_euclidean': 0.5832804782034675,\n",
       " 'spearman_euclidean': 0.6126055900254425,\n",
       " 'pearson_dot': 0.5086478770718181,\n",
       " 'spearman_dot': 0.5466362366701062,\n",
       " 'pearson_max': 0.595494529766493,\n",
       " 'spearman_max': 0.6172999437988739}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate our trained model\n",
    "evaluator(embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The one we are interested in most is 'pearson_cosine', which is the cosine similarity between centered vectors. It is a value between 0 and 1 where a higher value indicates higher degrees of similarity. We get a value of 0.59, which we consider a baseline throughout this chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Larger batch sizes tend to work better with multiple negative rankings (MNR) loss as a larger batch makes the task more difficult. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-Depth Evaluation\n",
    "\n",
    "A good embedding model is more than just a good score on the STSB benchmark! As we observed earlier, the GLUE benchmark has a number of tasks for which we can evaluate our embedding model. \n",
    "\n",
    " To unify this evaluation procedure, the Massive Text Embedding Benchmark (MTEB) was developed\n",
    "\n",
    " **The MTEB spans 8 embedding tasks that cover 58 datasets and 112 languages.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:mteb.evaluation.MTEB:Passing task names as strings is deprecated and will be removed in the next release. Please use `tasks = mteb.get_tasks(tasks=[...])` method to get tasks instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #262626; text-decoration-color: #262626\">───────────────────────────────────────────────── </span><span style=\"font-weight: bold\">Selected tasks </span><span style=\"color: #262626; text-decoration-color: #262626\"> ─────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;235m───────────────────────────────────────────────── \u001b[0m\u001b[1mSelected tasks \u001b[0m\u001b[38;5;235m ─────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Classification</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mClassification\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - Banking77Classification, <span style=\"color: #626262; text-decoration-color: #626262; font-style: italic\">s2s</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - Banking77Classification, \u001b[3;38;5;241ms2s\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# Choose evaluation task\n",
    "evaluation = MTEB(tasks=[\"Banking77Classification\"])\n",
    "\n",
    "# Calculate results\n",
    "results = evaluation.run(embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[MTEBResults(task_name=Banking77Classification, scores=...)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mteb_results = results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1240834/3408119087.py:1: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  mteb_results.dict()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dataset_revision': '0fd18e25b25c072e09e0d92ab615fda904d66300',\n",
       " 'task_name': 'Banking77Classification',\n",
       " 'mteb_version': '1.12.39',\n",
       " 'scores': {'test': [{'accuracy': 0.5904220779220779,\n",
       "    'f1': 0.5889991560371988,\n",
       "    'f1_weighted': 0.5889991560371988,\n",
       "    'scores_per_experiment': [{'accuracy': 0.587987012987013,\n",
       "      'f1': 0.5866559054728446,\n",
       "      'f1_weighted': 0.5866559054728445},\n",
       "     {'accuracy': 0.5743506493506494,\n",
       "      'f1': 0.5729107811455537,\n",
       "      'f1_weighted': 0.5729107811455536},\n",
       "     {'accuracy': 0.5928571428571429,\n",
       "      'f1': 0.5902115454600196,\n",
       "      'f1_weighted': 0.5902115454600197},\n",
       "     {'accuracy': 0.599025974025974,\n",
       "      'f1': 0.6004218246023643,\n",
       "      'f1_weighted': 0.6004218246023644},\n",
       "     {'accuracy': 0.6009740259740259,\n",
       "      'f1': 0.6003663902905382,\n",
       "      'f1_weighted': 0.6003663902905382},\n",
       "     {'accuracy': 0.6,\n",
       "      'f1': 0.5985031216347628,\n",
       "      'f1_weighted': 0.5985031216347628},\n",
       "     {'accuracy': 0.6006493506493507,\n",
       "      'f1': 0.597549621321672,\n",
       "      'f1_weighted': 0.5975496213216721},\n",
       "     {'accuracy': 0.5603896103896104,\n",
       "      'f1': 0.5602045308012714,\n",
       "      'f1_weighted': 0.5602045308012714},\n",
       "     {'accuracy': 0.6038961038961039,\n",
       "      'f1': 0.6005095420359257,\n",
       "      'f1_weighted': 0.6005095420359259},\n",
       "     {'accuracy': 0.5840909090909091,\n",
       "      'f1': 0.582658297607034,\n",
       "      'f1_weighted': 0.582658297607034}],\n",
       "    'main_score': 0.5904220779220779,\n",
       "    'hf_subset': 'default',\n",
       "    'languages': ['eng-Latn']}]},\n",
       " 'evaluation_time': 9.39578652381897,\n",
       " 'kg_co2_emissions': None}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mteb_results.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty and delete trainer/model\n",
    "trainer.accelerator.clear()\n",
    "del trainer, embedding_model\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Functions\n",
    "\n",
    "- Softmax loss is generally not advised as there are more performant losses. Instead:\n",
    "\n",
    "    - **Cosine similarity**: Cosine similarity loss is straightforward—it calculates the cosine similarity between the two embeddings of the two texts and compares that to the labeled similarity score. Cosine similarity loss intuitively works best using data where you have pairs of sentences and labels that indicate their similarity between 0 and 1.\n",
    "    - Multiple negatives ranking (MNR) loss\n",
    "\n",
    "See losses: https://www.sbert.net/docs/package_reference/sentence_transformer/losses.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity\n",
    "\n",
    "To use this loss with our NLI dataset, we need to convert the entailment (0), neutral (1), and contradiction (2) labels to values between 0 and 1. \n",
    "\n",
    "The entailment represents a high similarity between the sentences, so we give it a similarity score of 1. In contrast, since both neutral and contradiction represent dissimilarity, we give these labels a similarity score of 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNLI dataset from GLUE\n",
    "# 0 = entailment, 1 = neutral, 2 = contradiction\n",
    "train_dataset = load_dataset(\"glue\", \"mnli\", split=\"train\").select(range(50_000))\n",
    "train_dataset = train_dataset.remove_columns(\"idx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (neutral/contradiction)=0 and (entailment)=1\n",
    "mapping = {2: 0, 1: 0, 0:1}\n",
    "train_dataset = Dataset.from_dict({\n",
    "    \"sentence1\": train_dataset[\"premise\"],\n",
    "    \"sentence2\": train_dataset[\"hypothesis\"],\n",
    "    \"label\": [float(mapping[label]) for label in train_dataset[\"label\"]]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an embedding similarity evaluator for stsb\n",
    "val_sts = load_dataset('glue', 'stsb', split='validation')\n",
    "evaluator = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=val_sts[\"sentence1\"],\n",
    "    sentences2=val_sts[\"sentence2\"],\n",
    "    scores=[score/5 for score in val_sts[\"label\"]],\n",
    "    main_similarity=\"cosine\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name bert-base-uncased. Creating a new one with mean pooling.\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "embedding_model = SentenceTransformer('bert-base-uncased')\n",
    "\n",
    "# Loss function\n",
    "train_loss = losses.CosineSimilarityLoss(model=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training arguments\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"cosineloss_embedding_model\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=100,\n",
    "    fp16=True,\n",
    "    eval_steps=100,\n",
    "    logging_steps=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=embedding_model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    loss=train_loss,\n",
    "    evaluator=evaluator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f6f8f2dbc53484a976b4b9b72fc068c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2297, 'grad_norm': 1.8058668375015259, 'learning_rate': 5e-05, 'epoch': 0.06}\n",
      "{'loss': 0.1679, 'grad_norm': 2.009979009628296, 'learning_rate': 4.6582365003417636e-05, 'epoch': 0.13}\n",
      "{'loss': 0.1725, 'grad_norm': 1.6234655380249023, 'learning_rate': 4.316473000683528e-05, 'epoch': 0.19}\n",
      "{'loss': 0.1585, 'grad_norm': 1.1327171325683594, 'learning_rate': 3.9747095010252904e-05, 'epoch': 0.26}\n",
      "{'loss': 0.1538, 'grad_norm': 1.5563822984695435, 'learning_rate': 3.632946001367054e-05, 'epoch': 0.32}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45b1c267cbf5433f8b1fdf1c06ec10d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1574, 'grad_norm': 1.4668450355529785, 'learning_rate': 3.291182501708818e-05, 'epoch': 0.38}\n",
      "{'loss': 0.1533, 'grad_norm': 1.2550017833709717, 'learning_rate': 2.9494190020505813e-05, 'epoch': 0.45}\n",
      "{'loss': 0.1575, 'grad_norm': 1.3735573291778564, 'learning_rate': 2.6076555023923443e-05, 'epoch': 0.51}\n",
      "{'loss': 0.149, 'grad_norm': 1.4254496097564697, 'learning_rate': 2.2658920027341084e-05, 'epoch': 0.58}\n",
      "{'loss': 0.1468, 'grad_norm': 1.0495551824569702, 'learning_rate': 1.9241285030758715e-05, 'epoch': 0.64}\n",
      "{'loss': 0.148, 'grad_norm': 1.1007907390594482, 'learning_rate': 1.5823650034176352e-05, 'epoch': 0.7}\n",
      "{'loss': 0.1464, 'grad_norm': 1.0369843244552612, 'learning_rate': 1.2406015037593984e-05, 'epoch': 0.77}\n",
      "{'loss': 0.1449, 'grad_norm': 1.4250003099441528, 'learning_rate': 8.988380041011621e-06, 'epoch': 0.83}\n",
      "{'loss': 0.14, 'grad_norm': 1.3402336835861206, 'learning_rate': 5.570745044429255e-06, 'epoch': 0.9}\n",
      "{'loss': 0.1401, 'grad_norm': 1.1403541564941406, 'learning_rate': 2.15311004784689e-06, 'epoch': 0.96}\n",
      "{'train_runtime': 76.861, 'train_samples_per_second': 650.525, 'train_steps_per_second': 20.335, 'train_loss': 0.15715857339225667, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1563, training_loss=0.15715857339225667, metrics={'train_runtime': 76.861, 'train_samples_per_second': 650.525, 'train_steps_per_second': 20.335, 'total_flos': 0.0, 'train_loss': 0.15715857339225667, 'epoch': 1.0})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pearson_cosine': 0.7338387386384624,\n",
       " 'spearman_cosine': 0.7356435201309607,\n",
       " 'pearson_manhattan': 0.7431044662138206,\n",
       " 'spearman_manhattan': 0.7429445631964317,\n",
       " 'pearson_euclidean': 0.7429558955289768,\n",
       " 'spearman_euclidean': 0.7428646728011881,\n",
       " 'pearson_dot': 0.6999397043633594,\n",
       " 'spearman_dot': 0.6999497108007732,\n",
       " 'pearson_max': 0.7431044662138206,\n",
       " 'spearman_max': 0.7429445631964317}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate our trained model\n",
    "evaluator(embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Negatives Ranking Loss\n",
    "\n",
    "Multiple negatives ranking (MNR) loss, often referred to as InfoNCE or NTXentLoss is a loss that uses either positive pairs of sentences or triplets that **contain a pair of positive sentences and an additional unrelated sentence.** \n",
    "\n",
    "- **Negative pairs** are constructed by mixing a positive pair with another positive pair. These negatives are called **in-batch negatives** and can also be used to generate the triplets.\n",
    "\n",
    "After having generated these positive and negative pairs, we calculate their embeddings and apply cosine similarity. \n",
    "\n",
    "- These similarity scores are then used to answer the question, are these pairs negative or positive?  In other words, it is treated as a classification task and we can use **cross-entropy loss to optimize the model**.\n",
    "\n",
    "To make these triplets we start with an **anchor sentence** (i.e., labeled as the “premise”), which is used to compare other sentences.\n",
    "\n",
    "- we only select sentence pairs that are positive (i.e., labeled as “entailment”)\n",
    "- to add negative sentences, we randomly sample sentences as the “hypothesis.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load MNLI dataset from GLUE\n",
    "mnli = load_dataset(\"glue\", \"mnli\", split=\"train\").select(range(50_000))\n",
    "mnli = mnli.remove_columns(\"idx\")\n",
    "mnli = mnli.filter(lambda x: True if x['label'] == 0 else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16875it [00:00, 45839.20it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16875"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare data and add a soft negative\n",
    "train_dataset = {\"anchor\": [], \"positive\": [], \"negative\": []}\n",
    "soft_negatives = mnli[\"hypothesis\"]\n",
    "random.shuffle(soft_negatives)\n",
    "for row, soft_negative in tqdm(zip(mnli, soft_negatives)):\n",
    "    train_dataset[\"anchor\"].append(row[\"premise\"])\n",
    "    train_dataset[\"positive\"].append(row[\"hypothesis\"])\n",
    "    train_dataset[\"negative\"].append(soft_negative)\n",
    "train_dataset = Dataset.from_dict(train_dataset)\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anchor': 'How do you know? All this is their information again.',\n",
       " 'positive': 'This information belongs to them.',\n",
       " 'negative': \"They're pretty nice yes.\"}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anchor': \"my walkman broke so i'm upset now i just have to turn the stereo up real loud\",\n",
       " 'positive': \"I'm upset that my walkman broke and now I have to turn the stereo up really loud.\",\n",
       " 'negative': 'I asked what was wrong with the frosting.'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an embedding similarity evaluator for stsb\n",
    "val_sts = load_dataset('glue', 'stsb', split='validation')\n",
    "evaluator = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=val_sts[\"sentence1\"],\n",
    "    sentences2=val_sts[\"sentence2\"],\n",
    "    scores=[score/5 for score in val_sts[\"label\"]],\n",
    "    main_similarity=\"cosine\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "    num_rows: 1500\n",
       "})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_sts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name bert-base-uncased. Creating a new one with mean pooling.\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "embedding_model = SentenceTransformer('bert-base-uncased')\n",
    "\n",
    "# Loss function\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model=embedding_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training arguments\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"training_mnrloss_embedding_model\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=100,\n",
    "    fp16=True,\n",
    "    eval_steps=100,\n",
    "    logging_steps=100,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=embedding_model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    loss=train_loss,\n",
    "    evaluator=evaluator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb64f07a0b314c1cb028ff2d7e1850d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/528 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3277, 'grad_norm': 5.583022594451904, 'learning_rate': 4.85e-05, 'epoch': 0.19}\n",
      "{'loss': 0.1104, 'grad_norm': 4.510645866394043, 'learning_rate': 3.866822429906542e-05, 'epoch': 0.38}\n",
      "{'loss': 0.0783, 'grad_norm': 3.3987390995025635, 'learning_rate': 2.698598130841122e-05, 'epoch': 0.57}\n",
      "{'loss': 0.0677, 'grad_norm': 0.8355557918548584, 'learning_rate': 1.530373831775701e-05, 'epoch': 0.76}\n",
      "{'loss': 0.0688, 'grad_norm': 1.185404658317566, 'learning_rate': 3.6214953271028036e-06, 'epoch': 0.95}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7df1bf0ec82d419bb059a1020c0caee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 32.9937, 'train_samples_per_second': 511.461, 'train_steps_per_second': 16.003, 'train_loss': 0.1269701152588382, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=528, training_loss=0.1269701152588382, metrics={'train_runtime': 32.9937, 'train_samples_per_second': 511.461, 'train_steps_per_second': 16.003, 'total_flos': 0.0, 'train_loss': 0.1269701152588382, 'epoch': 1.0})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pearson_cosine': 0.8017746118354057,\n",
       " 'spearman_cosine': 0.806607378712418,\n",
       " 'pearson_manhattan': 0.8185531478394932,\n",
       " 'spearman_manhattan': 0.8146311493742627,\n",
       " 'pearson_euclidean': 0.8186071709577609,\n",
       " 'spearman_euclidean': 0.8147699590785977,\n",
       " 'pearson_dot': 0.7352056555456891,\n",
       " 'spearman_dot': 0.7235103433617001,\n",
       " 'pearson_max': 0.8186071709577609,\n",
       " 'spearman_max': 0.8147699590785977}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate our trained model\n",
    "evaluator(embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to have negatives that are very related to the question but not the right answer. These negatives are called **hard negatives**.\n",
    "\n",
    "\n",
    "Gathering negatives can roughly be divided into the following three processes:\n",
    "\n",
    "- **Easy negatives**: through randomly sampling documents as we did before.\n",
    "- **Semi-hard negatives**: using a pretrained embedding model, we can apply cosine similarity on all sentence embeddings to find those that are highly related. Generally, this does not lead to hard negatives since this method merely finds similar sentences, not question/answer pairs.\n",
    "- **Hard negatives**: these often need to be either manually labeled (for instance, by generating semi-hard negatives) or you can use a generative model to either judge or generate sentence pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning an Embedding Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section, we went through the basics of training an embedding model from scratch and saw how we could leverage loss functions to further optimize its performance. \n",
    "\n",
    "This approach, although quite powerful, requires creating an embedding model from scratch. This process can be quite costly and time-consuming.\n",
    "\n",
    "Instead, the sentence-transformers framework allows nearly all embedding models to be used as a base for fine-tuning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Fine-Tuning\n",
    "\n",
    "The most straightforward way to fine-tune an embedding model is to repeat the process of training our model as we did before but replace the 'bert-base-uncased' with a pretrained sentence-transformers model.\n",
    "\n",
    "There are many to choose from but generally, all-MiniLM-L6-v2 performs well across many use cases and due to its small size is quite fast.\n",
    "\n",
    "We use the same data as we used to train our model in the MNR loss example but instead use a pretrained embedding model to fine-tune. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNLI dataset from GLUE\n",
    "# 0 = entailment, 1 = neutral, 2 = contradiction\n",
    "train_dataset = load_dataset(\"glue\", \"mnli\", split=\"train\").select(range(50_000))\n",
    "train_dataset = train_dataset.remove_columns(\"idx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an embedding similarity evaluator for stsb\n",
    "val_sts = load_dataset('glue', 'stsb', split='validation')\n",
    "evaluator = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=val_sts[\"sentence1\"],\n",
    "    sentences2=val_sts[\"sentence2\"],\n",
    "    scores=[score/5 for score in val_sts[\"label\"]],\n",
    "    main_similarity=\"cosine\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74aaa339ace44de1aa45855b21bc550d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fa09db3f411431ba1b14d41e6a2172e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2a19d73ba594afbbac2d665d4b10ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "647f8c337cc5475ba9d1f05dd92b1c9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cccf0987ce0415fb70e40ca9a953bc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e3cf5cac9f247599f3596e087c75e05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8ca7821e4844b448f717d9a2164074b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5326048974b54b04962f108d5385461d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8f44d695d094f94b35da09a12395246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd897020a128419f83a06f7d67e69681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a3c3a7e9d054d6bada3cbf48f4a425c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define model\n",
    "embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training arguments\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"finetuned_embedding_model\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=100,\n",
    "    fp16=True,\n",
    "    eval_steps=100,\n",
    "    logging_steps=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=embedding_model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    loss=train_loss,\n",
    "    evaluator=evaluator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e272657667406ba28da764aa14f243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sentence_transformers.data_collator:Column 'hypothesis' is at index 1, whereas a column with this name is usually expected at index 0. Note that the column order can be important for some losses, e.g. MultipleNegativesRankingLoss will always consider the first column as the anchor and the second as the positive, regardless of the dataset column names. Consider renaming the columns to match the expected order, e.g.:\n",
      "dataset = dataset.select_columns(['hypothesis', 'entailment', 'contradiction'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1658, 'grad_norm': 3.795701265335083, 'learning_rate': 5e-05, 'epoch': 0.06}\n",
      "{'loss': 0.1092, 'grad_norm': 3.0204427242279053, 'learning_rate': 4.6582365003417636e-05, 'epoch': 0.13}\n",
      "{'loss': 0.1208, 'grad_norm': 2.0707175731658936, 'learning_rate': 4.316473000683528e-05, 'epoch': 0.19}\n",
      "{'loss': 0.1128, 'grad_norm': 3.7757997512817383, 'learning_rate': 3.9747095010252904e-05, 'epoch': 0.26}\n",
      "{'loss': 0.1098, 'grad_norm': 4.821083068847656, 'learning_rate': 3.632946001367054e-05, 'epoch': 0.32}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ce15f7dbe32458ea7c745c86a13de55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1005, 'grad_norm': 2.3958559036254883, 'learning_rate': 3.291182501708818e-05, 'epoch': 0.38}\n",
      "{'loss': 0.1183, 'grad_norm': 4.6376051902771, 'learning_rate': 2.9494190020505813e-05, 'epoch': 0.45}\n",
      "{'loss': 0.1015, 'grad_norm': 1.9947108030319214, 'learning_rate': 2.6076555023923443e-05, 'epoch': 0.51}\n",
      "{'loss': 0.1099, 'grad_norm': 1.2352083921432495, 'learning_rate': 2.2658920027341084e-05, 'epoch': 0.58}\n",
      "{'loss': 0.1011, 'grad_norm': 5.134367942810059, 'learning_rate': 1.9241285030758715e-05, 'epoch': 0.64}\n",
      "{'loss': 0.0932, 'grad_norm': 2.1828413009643555, 'learning_rate': 1.5823650034176352e-05, 'epoch': 0.7}\n",
      "{'loss': 0.106, 'grad_norm': 1.9396013021469116, 'learning_rate': 1.2406015037593984e-05, 'epoch': 0.77}\n",
      "{'loss': 0.1058, 'grad_norm': 2.8037314414978027, 'learning_rate': 8.988380041011621e-06, 'epoch': 0.83}\n",
      "{'loss': 0.105, 'grad_norm': 1.2151201963424683, 'learning_rate': 5.570745044429255e-06, 'epoch': 0.9}\n",
      "{'loss': 0.1074, 'grad_norm': 3.354924201965332, 'learning_rate': 2.15311004784689e-06, 'epoch': 0.96}\n",
      "{'train_runtime': 26.4611, 'train_samples_per_second': 1889.564, 'train_steps_per_second': 59.068, 'train_loss': 0.11024498771721174, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1563, training_loss=0.11024498771721174, metrics={'train_runtime': 26.4611, 'train_samples_per_second': 1889.564, 'train_steps_per_second': 59.068, 'total_flos': 0.0, 'train_loss': 0.11024498771721174, 'epoch': 1.0})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pearson_cosine': 0.8476046186902555,\n",
       " 'spearman_cosine': 0.8474595848409044,\n",
       " 'pearson_manhattan': 0.8501359286358263,\n",
       " 'spearman_manhattan': 0.8468474331729003,\n",
       " 'pearson_euclidean': 0.8508508761235378,\n",
       " 'spearman_euclidean': 0.8474595848409044,\n",
       " 'pearson_dot': 0.8476046173484233,\n",
       " 'spearman_dot': 0.8474595848409044,\n",
       " 'pearson_max': 0.8508508761235378,\n",
       " 'spearman_max': 0.8474595848409044}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate our trained model\n",
    "evaluator(embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TIP\n",
    "\n",
    "Instead of using a pretrained BERT model like 'bert-base-uncased' or a possible out-of-domain model like 'all-mpnet-base-v2', you can also perform **masked language modeling** on the pretrained BERT model to first adapt it to your domain.\n",
    "\n",
    " Then, you can use this fine-tuned BERT model as the base for training your embedding model.\n",
    "\n",
    " This is a form of **domain adaptation** (*In the next chapter, we will apply masked language modeling on a pretrained model.*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmented SBERT\n",
    "\n",
    "A disadvantage of training or fine-tuning these embedding models is that they often require substantial training data. \n",
    "\n",
    "Extracting such a high number of sentence pairs for your use case is generally not possible as in many cases, there are only a couple of thousand labeled data points available.\n",
    "\n",
    "Fortunately, there is a way to augment your data such that an embedding model can be fine-tuned when there is only a little labeled data available. This procedure is referred to as **Augmented SBERT**\n",
    "\n",
    "In this procedure, we aim to augment the small amount of labeled data such that they can be used for regular training. It makes use of the slow and more accurate cross-encoder architecture (BERT) to augment and label a larger set of input pairs. These newly labeled pairs are then used for fine-tuning a bi-encoder (SBERT). The steps are:\n",
    "\n",
    "- Fine-tune a cross-encoder (BERT) using a small, annotated dataset (gold dataset).\n",
    "- Create new sentence pairs.\n",
    "- Label new sentence pairs with the fine-tuned cross-encoder (silver dataset).\n",
    "- Train a bi-encoder (SBERT) on the extended dataset (gold + silver dataset).\n",
    "\n",
    "# <img src=\"imgs/augmentedsbert.png\" alt=\"Patching\" width=\"500\" height=\"200\">\n",
    "\n",
    "Augmented SBERT works through training a cross-encoder on a small gold dataset, then using that to label an unlabeled dataset to generate a larger silver dataset. Finally, both the gold and silver datasets are used to train the bi-encoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start fine-tuning Augmented SBERT\n",
    "\n",
    " Instead of our original 50,000 documents, we take a subset of 10,000 documents to simulate a setting where we have limited annotated data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a small set of 10000 documents for the cross-encoder\n",
    "dataset = load_dataset(\"glue\", \"mnli\", split=\"train\").select(range(10_000))\n",
    "mapping = {2: 0, 1: 0, 0:1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 78329.69it/s]\n"
     ]
    }
   ],
   "source": [
    "# Data Loader\n",
    "gold_examples = [\n",
    "    InputExample(texts=[row[\"premise\"], row[\"hypothesis\"]], label=mapping[row[\"label\"]])\n",
    "    for row in tqdm(dataset)\n",
    "]\n",
    "gold_dataloader = NoDuplicatesDataLoader(gold_examples, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas DataFrame for easier data handling\n",
    "gold = pd.DataFrame(\n",
    "    {\n",
    "    'sentence1': dataset['premise'],\n",
    "    'sentence2': dataset['hypothesis'],\n",
    "    'label': [mapping[label] for label in dataset['label']]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Conceptually cream skimming has two basic dime...</td>\n",
       "      <td>Product and geography are what make cream skim...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you know during the season and i guess at at y...</td>\n",
       "      <td>You lose the things to the following level if ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One of our number will carry out your instruct...</td>\n",
       "      <td>A member of my team will execute your orders w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do you know? All this is their information...</td>\n",
       "      <td>This information belongs to them.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yeah i tell you what though if you go price so...</td>\n",
       "      <td>The tennis shoes have a range of prices.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Because, despite its monopoly power, Microsoft...</td>\n",
       "      <td>Microsoft owns 60 percent of all computer-rela...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>'Right,' I mumbled.</td>\n",
       "      <td>'Wrong', I said.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Thanks dad.</td>\n",
       "      <td>Thanks Obama.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>which is good</td>\n",
       "      <td>I don't think that's great</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Their breath came in clouds in the cool night ...</td>\n",
       "      <td>Their breath was invisible in the hot air.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence1  \\\n",
       "0     Conceptually cream skimming has two basic dime...   \n",
       "1     you know during the season and i guess at at y...   \n",
       "2     One of our number will carry out your instruct...   \n",
       "3     How do you know? All this is their information...   \n",
       "4     yeah i tell you what though if you go price so...   \n",
       "...                                                 ...   \n",
       "9995  Because, despite its monopoly power, Microsoft...   \n",
       "9996                                'Right,' I mumbled.   \n",
       "9997                                        Thanks dad.   \n",
       "9998                                      which is good   \n",
       "9999  Their breath came in clouds in the cool night ...   \n",
       "\n",
       "                                              sentence2  label  \n",
       "0     Product and geography are what make cream skim...      0  \n",
       "1     You lose the things to the following level if ...      1  \n",
       "2     A member of my team will execute your orders w...      1  \n",
       "3                     This information belongs to them.      1  \n",
       "4              The tennis shoes have a range of prices.      0  \n",
       "...                                                 ...    ...  \n",
       "9995  Microsoft owns 60 percent of all computer-rela...      0  \n",
       "9996                                  'Wrong', I said.       0  \n",
       "9997                                     Thanks Obama.       0  \n",
       "9998                         I don't think that's great      0  \n",
       "9999         Their breath was invisible in the hot air.      0  \n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Train a cross-encoder on the gold dataset\n",
    "cross_encoder = CrossEncoder('bert-base-uncased', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_encoder.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(gold_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Random CWC inspections, Bork says, violate the Fourth Amendment, which requires a warrant to search private facilities.',\n",
       " 'They do not have a warrant to conduct these random inspections.']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3062f5af8d64df688532aaf35131a89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a67b8c3739f340a291ad0eba221893d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gold_dataloader = NoDuplicatesDataLoader(gold_examples, batch_size=32)\n",
    "cross_encoder.fit(\n",
    "    train_dataloader=gold_dataloader,\n",
    "    epochs=1,\n",
    "    show_progress_bar=True,\n",
    "    warmup_steps=100,\n",
    "    use_amp=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training our cross-encoder, we use the remaining 40,000 sentence pairs (from our original dataset of 50,000 sentence pairs) as our silver dataset (step 2):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** Create new sentence pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the silver dataset by predicting labels with the cross-encoder\n",
    "silver = load_dataset(\n",
    "    \"glue\", \"mnli\", split=\"train\"\n",
    ").select(range(10_000, 50_000))\n",
    "pairs = list(zip(silver[\"premise\"], silver[\"hypothesis\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Hindus and Buddhists still bathe where he bathed.',\n",
       " 'Hindus and Buddhists bathe in the same location.')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** Label new sentence pairs with the fine-tuned cross-encoder (silver dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d4533b6c2b4fba8252ef5e3364bdb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Label the sentence pairs using our fine-tuned cross-encoder\n",
    "output = cross_encoder.predict(pairs, apply_softmax=True, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 2)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.32352844, 0.67647153],\n",
       "       [0.9028155 , 0.09718444],\n",
       "       [0.9230069 , 0.07699306],\n",
       "       ...,\n",
       "       [0.8280179 , 0.17198205],\n",
       "       [0.23569162, 0.76430833],\n",
       "       [0.15352033, 0.8464796 ]], dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "silver = pd.DataFrame(\n",
    "    {\n",
    "        \"sentence1\": silver[\"premise\"], \n",
    "        \"sentence2\": silver[\"hypothesis\"],\n",
    "        \"label\": np.argmax(output, axis=1)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hindus and Buddhists still bathe where he bathed.</td>\n",
       "      <td>Hindus and Buddhists bathe in the same location.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Probably no one will even notice you at all.\"</td>\n",
       "      <td>Everyone will know who you are.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>well what what do you mean if they can prove i...</td>\n",
       "      <td>You don't need to say anymore about the matter...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I feel dizzy.</td>\n",
       "      <td>The dizziness I feel is from drinking.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Well, he did, sir.</td>\n",
       "      <td>Sir, well, he did complete it before he left l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>It was a cop, a woman of intermediate age.</td>\n",
       "      <td>The police were after us.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>In Trinidad, Motel Las Cuevas has a disco with...</td>\n",
       "      <td>There is a disco in Motel Las Cuevas.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>Tommy's heart sank at the sight of them.</td>\n",
       "      <td>The sight of them cheered Tommy up.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>Wodehouse, Paul Gigot and Mary McGrory.</td>\n",
       "      <td>Paul Gigot and others.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>Democrats think they're immune to this attack ...</td>\n",
       "      <td>Democrats think they have covered both ends of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence1  \\\n",
       "0      Hindus and Buddhists still bathe where he bathed.   \n",
       "1          Probably no one will even notice you at all.\"   \n",
       "2      well what what do you mean if they can prove i...   \n",
       "3                                          I feel dizzy.   \n",
       "4                                     Well, he did, sir.   \n",
       "...                                                  ...   \n",
       "39995         It was a cop, a woman of intermediate age.   \n",
       "39996  In Trinidad, Motel Las Cuevas has a disco with...   \n",
       "39997           Tommy's heart sank at the sight of them.   \n",
       "39998            Wodehouse, Paul Gigot and Mary McGrory.   \n",
       "39999  Democrats think they're immune to this attack ...   \n",
       "\n",
       "                                               sentence2  label  \n",
       "0       Hindus and Buddhists bathe in the same location.      1  \n",
       "1                        Everyone will know who you are.      0  \n",
       "2      You don't need to say anymore about the matter...      0  \n",
       "3                 The dizziness I feel is from drinking.      0  \n",
       "4      Sir, well, he did complete it before he left l...      0  \n",
       "...                                                  ...    ...  \n",
       "39995                          The police were after us.      0  \n",
       "39996              There is a disco in Motel Las Cuevas.      1  \n",
       "39997                The sight of them cheered Tommy up.      0  \n",
       "39998                             Paul Gigot and others.      1  \n",
       "39999  Democrats think they have covered both ends of...      1  \n",
       "\n",
       "[40000 rows x 3 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:** Train a bi-encoder (SBERT) on the extended dataset (gold + silver dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine gold + silver\n",
    "data = pd.concat([gold, silver], ignore_index=True, axis=0)\n",
    "data = data.drop_duplicates(subset=['sentence1', 'sentence2'], keep=\"first\")\n",
    "train_dataset = Dataset.from_pandas(data, preserve_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49998"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an embedding similarity evaluator for stsb\n",
    "val_sts = load_dataset('glue', 'stsb', split='validation')\n",
    "evaluator = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=val_sts[\"sentence1\"],\n",
    "    sentences2=val_sts[\"sentence2\"],\n",
    "    scores=[score/5 for score in val_sts[\"label\"]],\n",
    "    main_similarity=\"cosine\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name bert-base-uncased. Creating a new one with mean pooling.\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "embedding_model = SentenceTransformer('bert-base-uncased')\n",
    "\n",
    "# Loss function\n",
    "train_loss = losses.CosineSimilarityLoss(model=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training arguments\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"augmented_embedding_model\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=100,\n",
    "    fp16=True,\n",
    "    eval_steps=100,\n",
    "    logging_steps=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=embedding_model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    loss=train_loss,\n",
    "    evaluator=evaluator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e82d3ba118bf46daaa5f98b92fa26639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2244, 'grad_norm': 1.6568797826766968, 'learning_rate': 5e-05, 'epoch': 0.06}\n",
      "{'loss': 0.1649, 'grad_norm': 1.353955864906311, 'learning_rate': 4.6582365003417636e-05, 'epoch': 0.13}\n",
      "{'loss': 0.1495, 'grad_norm': 1.5114811658859253, 'learning_rate': 4.316473000683528e-05, 'epoch': 0.19}\n",
      "{'loss': 0.1454, 'grad_norm': 1.3773846626281738, 'learning_rate': 3.9747095010252904e-05, 'epoch': 0.26}\n",
      "{'loss': 0.1451, 'grad_norm': 1.428134799003601, 'learning_rate': 3.632946001367054e-05, 'epoch': 0.32}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2f0e34b5a91468da3379282194025e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1413, 'grad_norm': 0.9189131855964661, 'learning_rate': 3.291182501708818e-05, 'epoch': 0.38}\n",
      "{'loss': 0.1379, 'grad_norm': 1.5339771509170532, 'learning_rate': 2.9494190020505813e-05, 'epoch': 0.45}\n",
      "{'loss': 0.1344, 'grad_norm': 1.3115142583847046, 'learning_rate': 2.6076555023923443e-05, 'epoch': 0.51}\n",
      "{'loss': 0.1396, 'grad_norm': 1.3162517547607422, 'learning_rate': 2.2658920027341084e-05, 'epoch': 0.58}\n",
      "{'loss': 0.1379, 'grad_norm': 2.0594136714935303, 'learning_rate': 1.9241285030758715e-05, 'epoch': 0.64}\n",
      "{'loss': 0.134, 'grad_norm': 1.292578935623169, 'learning_rate': 1.5823650034176352e-05, 'epoch': 0.7}\n",
      "{'loss': 0.138, 'grad_norm': 1.0106781721115112, 'learning_rate': 1.2406015037593984e-05, 'epoch': 0.77}\n",
      "{'loss': 0.135, 'grad_norm': 1.2033296823501587, 'learning_rate': 8.988380041011621e-06, 'epoch': 0.83}\n",
      "{'loss': 0.1341, 'grad_norm': 1.5598094463348389, 'learning_rate': 5.570745044429255e-06, 'epoch': 0.9}\n",
      "{'loss': 0.1334, 'grad_norm': 0.9005824327468872, 'learning_rate': 2.15311004784689e-06, 'epoch': 0.96}\n",
      "{'train_runtime': 77.1952, 'train_samples_per_second': 647.682, 'train_steps_per_second': 20.247, 'train_loss': 0.1456825832335215, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1563, training_loss=0.1456825832335215, metrics={'train_runtime': 77.1952, 'train_samples_per_second': 647.682, 'train_steps_per_second': 20.247, 'total_flos': 0.0, 'train_loss': 0.1456825832335215, 'epoch': 1.0})"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pearson_cosine': 0.697684514280203,\n",
       " 'spearman_cosine': 0.7006963038426953,\n",
       " 'pearson_manhattan': 0.7203120291872793,\n",
       " 'spearman_manhattan': 0.7170015019278266,\n",
       " 'pearson_euclidean': 0.7200757173710048,\n",
       " 'spearman_euclidean': 0.7167987301830531,\n",
       " 'pearson_dot': 0.6446288153738338,\n",
       " 'spearman_dot': 0.6430106252431572,\n",
       " 'pearson_max': 0.7203120291872793,\n",
       " 'spearman_max': 0.7170015019278266}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate our trained model\n",
    "evaluator(embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create an embedding model, we typically need labeled data. However, not all real-world datasets come with a nice set of labels that we can use. \n",
    "\n",
    " We instead look for techniques to train the model without any predetermined labels—unsupervised learning.\n",
    "\n",
    " Many approaches exist, like:\n",
    " \n",
    "- Simple Contrastive Learning of Sentence Embeddings (SimCSE)\n",
    "- Contrastive Tension (CT)\n",
    "- Transformer-based Sequential Denoising Auto-Encoder (TSDAE)\n",
    "- Generative Pseudo-Labeling (GPL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer-Based Sequential Denoising Auto-Encoder (TSDAE)\n",
    "\n",
    "The underlying idea of TSDAE is that we **add noise** to the input sentence by removing a certain percentage of words from it. \n",
    "\n",
    "This “damaged” sentence is put through an encoder, with a pooling layer on top of it, to map it to a sentence embedding\n",
    "\n",
    "From this sentence embedding, a decoder tries to reconstruct the original sentence from the “damaged” sentence but without the artificial noise.\n",
    "\n",
    "The main concept here is that the more accurate the sentence embedding is, the more accurate the reconstructed sentence will be.\n",
    "\n",
    "**This method is very similar to masked language modeling, where we try to reconstruct and learn certain masked words. Here, instead of reconstructing masked words, we try to reconstruct the entire sentence.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/tsdae.png\" alt=\"Hugging Face\" height=400 width=500>\n",
    "\n",
    "*Caption*:  TSDAE randomly removes words from an input sentence that is passed through an encoder to generate a sentence embedding. From this sentence embedding, the original sentence is reconstructed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, we can use the encoder to generate embeddings from text since the decoder is only used for judging whether the embeddings can accurately reconstruct the original sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we only need a bunch of sentences without any labels, training this model is straightforward. We start by downloading an external tokenizer, which is used for the denoising procedure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/david/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download additional tokenizer\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we create flat sentences from our data and remove any labels that we have to mimic an unsupervised setting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a flat list of sentences\n",
    "mnli = load_dataset(\"glue\", \"mnli\", split=\"train\").select(range(25_000))\n",
    "flat_sentences = mnli[\"premise\"] + mnli[\"hypothesis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add noise to our input data\n",
    "damaged_data = DenoisingAutoEncoderDataset(list(set(flat_sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = damaged_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['waste associated costs',\n",
       " 'Hazardous waste disposal has some associated costs.']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example.texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48353/48353 [00:03<00:00, 13440.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create dataset\n",
    "train_dataset = {\"damaged_sentence\": [], \"original_sentence\": []}\n",
    "for data in tqdm(damaged_data):\n",
    "    train_dataset[\"damaged_sentence\"].append(data.texts[0])\n",
    "    train_dataset[\"original_sentence\"].append(data.texts[1])\n",
    "train_dataset = Dataset.from_dict(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'damaged_sentence': 'waste disposal has costs',\n",
       " 'original_sentence': 'Hazardous waste disposal has some associated costs.'}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an embedding similarity evaluator for stsb\n",
    "val_sts = load_dataset('glue', 'stsb', split='validation')\n",
    "evaluator = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=val_sts[\"sentence1\"],\n",
    "    sentences2=val_sts[\"sentence2\"],\n",
    "    scores=[score/5 for score in val_sts[\"label\"]],\n",
    "    main_similarity=\"cosine\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we run the training as before but with the [CLS] token as the pooling strategy instead of the mean pooling of the token embeddings. In the TSDAE paper, this was shown to be more effective since mean pooling loses the position information, which is not the case when using the [CLS] token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your embedding model\n",
    "word_embedding_model = models.Transformer('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: BertModel "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(word_embedding_model.modules())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(), 'cls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our sentence pairs, we will need a loss function that attempts to reconstruct the original sentence using the noise sentence, namely DenoisingAutoEncoderLoss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, we tie the parameters of both models. Instead of having separate weights for the encoder’s embedding layer and the decoder’s output layer, they share the same weights. This means that any updates to the weights in one layer will be reflected in the other layer as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertLMHeadModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.value.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following encoder weights were not tied to the decoder ['bert/pooler']\n"
     ]
    }
   ],
   "source": [
    "# Use the denoising auto-encoder loss\n",
    "train_loss = losses.DenoisingAutoEncoderLoss(\n",
    "    embedding_model, tie_encoder_decoder=True\n",
    ")\n",
    "train_loss.decoder = train_loss.decoder.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, training our model works the same as we have seen several times before but we lower the batch size as memory increases with this loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training arguments\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"training_tsdae_embedding_model\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=100,\n",
    "    fp16=True,\n",
    "    eval_steps=100,\n",
    "    logging_steps=100,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=embedding_model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    loss=train_loss,\n",
    "    evaluator=evaluator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9c1ae6c32734d2db370079011f1cd35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3023 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.9358, 'grad_norm': 9.466378211975098, 'learning_rate': 4.9e-05, 'epoch': 0.03}\n",
      "{'loss': 4.8196, 'grad_norm': 6.414368152618408, 'learning_rate': 4.8323640095791995e-05, 'epoch': 0.07}\n",
      "{'loss': 4.605, 'grad_norm': 7.210152626037598, 'learning_rate': 4.66130687649675e-05, 'epoch': 0.1}\n",
      "{'loss': 4.4569, 'grad_norm': 7.5083160400390625, 'learning_rate': 4.4902497434143e-05, 'epoch': 0.13}\n",
      "{'loss': 4.3871, 'grad_norm': 6.3871750831604, 'learning_rate': 4.319192610331851e-05, 'epoch': 0.17}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51355b2c41d747a0b8e9d2f049de9340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.2901, 'grad_norm': 6.639077663421631, 'learning_rate': 4.1481354772494014e-05, 'epoch': 0.2}\n",
      "{'loss': 4.2378, 'grad_norm': 6.110928058624268, 'learning_rate': 3.977078344166952e-05, 'epoch': 0.23}\n",
      "{'loss': 4.1407, 'grad_norm': 7.846587657928467, 'learning_rate': 3.806021211084502e-05, 'epoch': 0.26}\n",
      "{'loss': 4.1004, 'grad_norm': 7.981261253356934, 'learning_rate': 3.634964078002053e-05, 'epoch': 0.3}\n",
      "{'loss': 4.0651, 'grad_norm': 5.656072616577148, 'learning_rate': 3.463906944919603e-05, 'epoch': 0.33}\n",
      "{'loss': 4.0565, 'grad_norm': 6.975688457489014, 'learning_rate': 3.2928498118371536e-05, 'epoch': 0.36}\n",
      "{'loss': 3.9328, 'grad_norm': 6.082306385040283, 'learning_rate': 3.121792678754704e-05, 'epoch': 0.4}\n",
      "{'loss': 3.9532, 'grad_norm': 6.799237251281738, 'learning_rate': 2.9507355456722545e-05, 'epoch': 0.43}\n",
      "{'loss': 3.8724, 'grad_norm': 7.174602031707764, 'learning_rate': 2.7796784125898052e-05, 'epoch': 0.46}\n",
      "{'loss': 3.8855, 'grad_norm': 5.872269153594971, 'learning_rate': 2.6086212795073555e-05, 'epoch': 0.5}\n",
      "{'loss': 3.824, 'grad_norm': 5.505883693695068, 'learning_rate': 2.437564146424906e-05, 'epoch': 0.53}\n",
      "{'loss': 3.8279, 'grad_norm': 7.272131443023682, 'learning_rate': 2.2665070133424564e-05, 'epoch': 0.56}\n",
      "{'loss': 3.7817, 'grad_norm': 6.2796430587768555, 'learning_rate': 2.095449880260007e-05, 'epoch': 0.6}\n",
      "{'loss': 3.7529, 'grad_norm': 6.448436737060547, 'learning_rate': 1.9243927471775574e-05, 'epoch': 0.63}\n",
      "{'loss': 3.7712, 'grad_norm': 6.49161958694458, 'learning_rate': 1.753335614095108e-05, 'epoch': 0.66}\n",
      "{'loss': 3.7254, 'grad_norm': 6.134570598602295, 'learning_rate': 1.5822784810126583e-05, 'epoch': 0.69}\n",
      "{'loss': 3.6819, 'grad_norm': 6.7136030197143555, 'learning_rate': 1.4112213479302088e-05, 'epoch': 0.73}\n",
      "{'loss': 3.6571, 'grad_norm': 7.281564235687256, 'learning_rate': 1.2401642148477593e-05, 'epoch': 0.76}\n",
      "{'loss': 3.6647, 'grad_norm': 6.594813823699951, 'learning_rate': 1.0691070817653097e-05, 'epoch': 0.79}\n",
      "{'loss': 3.6477, 'grad_norm': 6.091384410858154, 'learning_rate': 8.980499486828602e-06, 'epoch': 0.83}\n",
      "{'loss': 3.616, 'grad_norm': 6.290093421936035, 'learning_rate': 7.269928156004106e-06, 'epoch': 0.86}\n",
      "{'loss': 3.658, 'grad_norm': 7.373635768890381, 'learning_rate': 5.55935682517961e-06, 'epoch': 0.89}\n",
      "{'loss': 3.6058, 'grad_norm': 7.778030872344971, 'learning_rate': 3.848785494355115e-06, 'epoch': 0.93}\n",
      "{'loss': 3.5894, 'grad_norm': 6.8026041984558105, 'learning_rate': 2.1382141635306195e-06, 'epoch': 0.96}\n",
      "{'loss': 3.603, 'grad_norm': 6.605139255523682, 'learning_rate': 4.276428327061239e-07, 'epoch': 0.99}\n",
      "{'train_runtime': 172.8166, 'train_samples_per_second': 279.794, 'train_steps_per_second': 17.493, 'train_loss': 4.034782010910332, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3023, training_loss=4.034782010910332, metrics={'train_runtime': 172.8166, 'train_samples_per_second': 279.794, 'train_steps_per_second': 17.493, 'total_flos': 0.0, 'train_loss': 4.034782010910332, 'epoch': 1.0})"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pearson_cosine': 0.7331246985650315,\n",
       " 'spearman_cosine': 0.7400307035317102,\n",
       " 'pearson_manhattan': 0.7306657513545326,\n",
       " 'spearman_manhattan': 0.7335406002926033,\n",
       " 'pearson_euclidean': 0.7310164658364212,\n",
       " 'spearman_euclidean': 0.7335530400406114,\n",
       " 'pearson_dot': 0.6425985295271535,\n",
       " 'spearman_dot': 0.6431215653931609,\n",
       " 'pearson_max': 0.7331246985650315,\n",
       " 'spearman_max': 0.7400307035317102}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate our trained model\n",
    "evaluator(embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain Adaptation\n",
    "\n",
    "When you have very little or no labeled data available, you typically use unsupervised learning to create your text embedding model. However, unsupervised techniques are generally outperformed by supervised techniques and **have difficulty learning domain-specific concepts.**\n",
    "\n",
    "**This is where domain adaptation comes in. Its goal is to update existing embedding models to a specific textual domain**\n",
    "\n",
    "The target domain, or out-domain, generally contains words and subjects that were not found in the source domain or in-domain.\n",
    "\n",
    "**In domain adaptation, the aim is to create and generalize an embedding model from one domain to another.**\n",
    "\n",
    "\n",
    "### Adaptative Pre-Training\n",
    "\n",
    "One method for domain adaptation is called adaptive pretraining.\n",
    "\n",
    "- You start by pretraining your domain-specific corpus using an unsupervised technique, such as the previously discussed TSDAE or  masked language modeling\n",
    "- you fine-tune that model using a training dataset that can be either outside or in your target domain (*although data from the target domain is preferred, out-domain data also works since we started with unsupervised training on the target domain.*)\n",
    "\n",
    "<img src=\"imgs/adaptivepretrain.png\" alt=\"Hugging Face\" height=400 width=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kr_hollm",
   "language": "python",
   "name": "kr_hollm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
