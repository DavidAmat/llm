{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RLHF and DPO are methods that can be used to teach the LLM to prefer one answer style over the other, that is, aligning better with user preferences\n",
    "- The RLHF process, which requires training a separate reward model, is outlined below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/dpo/4.webp\" width=600px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compared to RLHF, DPO aims to simplify the process by **optimizing models directly for user preferences without the need for complex reward modeling** and **policy optimization**\n",
    "- In other words, DPO focuses on directly optimizing the model's output to align with human preferences or specific objectives\n",
    "- Shown below is the main idea as an overview of how DPO works\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/dpo/5.webp?123\" width=600px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The concrete equation to implement the DPO loss is shown below; we will revisit the equation when we implement it in Python further down in this code notebook\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/dpo/3.webp?123\" width=600px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "# 2) Preparing a preference dataset for DPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here, we work with a dataset that contains more polite and less polite responses to instruction prompts (concrete examples are shown in the next section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The dataset was generated via the [create-preference-data-ollama.ipynb](create-preference-data-ollama.ipynb) notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "file_path = \"/home/david/Documents/data_science/datasets/instruction-finetuning/instruction-data-with-preference.json\"\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Identify the correct spelling of the following word.',\n",
      " 'input': 'Ocassion',\n",
      " 'output': \"The correct spelling is 'Occasion.'\",\n",
      " 'rejected': \"The correct spelling is obviously 'Occasion.'\",\n",
      " 'chosen': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pp(data[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': \"What is an antonym of 'complicated'?\",\n",
      " 'input': '',\n",
      " 'output': \"An antonym of 'complicated' is 'simple'.\",\n",
      " 'chosen': \"A suitable antonym for 'complicated' would be 'simple'.\",\n",
      " 'rejected': \"An antonym of 'complicated' is 'simple'.\"}\n"
     ]
    }
   ],
   "source": [
    "pprint.pp(data[999])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alpaca Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[50])\n",
    "print(model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "desired_response = f\"### Response:\\n{data[50]['chosen']}\"\n",
    "print(desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Response:\n",
      "The correct spelling is obviously 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "possible_response = f\"### Response:\\n{data[50]['rejected']}\"\n",
    "print(possible_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "## 2.2) Creating training, validation, and test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_portion = int(len(data) * 0.85)  # 85% for training\n",
    "test_portion = int(len(data) * 0.1)    # 10% for testing\n",
    "val_portion = len(data) - train_portion - test_portion  # Remaining 5% for validation\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "## 2.3) Developing a `PreferenceDataset` class and batch processing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class PreferenceDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            prompt = format_input(entry)\n",
    "            rejected_response = entry[\"rejected\"]\n",
    "            chosen_response = entry[\"chosen\"]\n",
    "\n",
    "            prompt_tokens = tokenizer.encode(prompt)\n",
    "            chosen_full_text = f\"{prompt}\\n\\n### Response:\\n{chosen_response}\"\n",
    "            rejected_full_text = f\"{prompt}\\n\\n### Response:\\n{rejected_response}\"\n",
    "            chosen_full_tokens = tokenizer.encode(chosen_full_text)\n",
    "            rejected_full_tokens = tokenizer.encode(rejected_full_text)\n",
    "\n",
    "            self.encoded_texts.append({\n",
    "                \"prompt\": prompt_tokens,\n",
    "                \"chosen\": chosen_full_tokens,\n",
    "                \"rejected\": rejected_full_tokens,\n",
    "            })\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Along with an updated `PreferenceDataset` class, we also need an updated batch collation function that we use to pad the sequences in each batch to an equal length so that we can assemble them in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    allowed_max_length=None,\n",
    "    mask_prompt_tokens=True,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Initialize lists to hold batch data\n",
    "    batch_data = {\n",
    "        \"prompt\": [],\n",
    "        \"chosen\": [],\n",
    "        \"rejected\": [],\n",
    "        \"rejected_mask\": [],\n",
    "        \"chosen_mask\": []\n",
    "\n",
    "    }\n",
    "\n",
    "    # Determine the longest sequence to set a common padding length\n",
    "    max_length_common = 0\n",
    "    if batch:\n",
    "        for key in [\"chosen\", \"rejected\"]:\n",
    "            current_max = max(len(item[key])+1 for item in batch)\n",
    "            max_length_common = max(max_length_common, current_max)\n",
    "\n",
    "    # Process each item in the batch\n",
    "    for item in batch:\n",
    "        prompt = torch.tensor(item[\"prompt\"])\n",
    "        batch_data[\"prompt\"].append(prompt)\n",
    "\n",
    "        for key in [\"chosen\", \"rejected\"]:\n",
    "            # Adjust padding according to the common maximum length\n",
    "            sequence = item[key]\n",
    "            padded = sequence + [pad_token_id] * (max_length_common - len(sequence))\n",
    "            mask = torch.ones(len(padded)).bool()\n",
    "\n",
    "            # Set mask for all padding tokens to False\n",
    "            mask[len(sequence):] = False\n",
    "\n",
    "            # Set mask for all input tokens to False\n",
    "            # +2 sets the 2 newline (\"\\n\") tokens before \"### Response\" to False\n",
    "            if mask_prompt_tokens:\n",
    "                mask[:prompt.shape[0]+2] = False\n",
    "\n",
    "            batch_data[key].append(torch.tensor(padded))\n",
    "            batch_data[f\"{key}_mask\"].append(mask)\n",
    "\n",
    "    # Final processing\n",
    "    for key in [\"chosen\", \"rejected\", \"chosen_mask\", \"rejected_mask\"]:\n",
    "        # Stack all sequences into a tensor for the given key\n",
    "        tensor_stack = torch.stack(batch_data[key])\n",
    "\n",
    "        # Optionally truncate to maximum sequence length\n",
    "        if allowed_max_length is not None:\n",
    "            tensor_stack = tensor_stack[:, :allowed_max_length]\n",
    "\n",
    "        # Move to the specified device\n",
    "        batch_data[key] = tensor_stack.to(device)\n",
    "\n",
    "    return batch_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect this collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "customized_collate_fn = partial(\n",
    "    custom_collate_fn,\n",
    "    device=device,            # Put the data directly on a GPU if available\n",
    "    mask_prompt_tokens=True,  # This is optional\n",
    "    allowed_max_length=1024   # The supported context length of the model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'instruction': 'Evaluate the following phrase by transforming it into the '\n",
      "                'spelling given.',\n",
      " 'input': 'freind --> friend',\n",
      " 'output': 'The spelling of the given phrase \"freind\" is incorrect, the '\n",
      "           'correct spelling is \"friend\".',\n",
      " 'rejected': 'The spelling of the given phrase \"freind\" is flat out wrong, get '\n",
      "             'it together, the correct spelling is \"friend\".',\n",
      " 'chosen': 'The spelling of the given phrase \"freind\" is incorrect, the '\n",
      "           'correct spelling is \"friend\".'}\n",
      "\n",
      "{'instruction': 'Edit the following sentence for grammar.',\n",
      " 'input': 'He go to the park every day.',\n",
      " 'output': 'He goes to the park every day.',\n",
      " 'rejected': 'He goes to the stupid park every single day.',\n",
      " 'chosen': 'He goes to the park every day.'}\n"
     ]
    }
   ],
   "source": [
    "example_data = data[:2]\n",
    "\n",
    "for i in example_data:\n",
    "    print()\n",
    "    pprint.pp(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'instruction': 'Evaluate the following phrase by transforming it into the spelling given.',\n",
       "  'input': 'freind --> friend',\n",
       "  'output': 'The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".',\n",
       "  'rejected': 'The spelling of the given phrase \"freind\" is flat out wrong, get it together, the correct spelling is \"friend\".',\n",
       "  'chosen': 'The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".'},\n",
       " {'instruction': 'Edit the following sentence for grammar.',\n",
       "  'input': 'He go to the park every day.',\n",
       "  'output': 'He goes to the park every day.',\n",
       "  'rejected': 'He goes to the stupid park every single day.',\n",
       "  'chosen': 'He goes to the park every day.'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Next, let's instantiate an `example_dataset` and use a PyTorch `DataLoader` to create an `example_dataloader` that mimics the data loader we will use for the model training later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "example_dataset = PreferenceDataset(example_data, tokenizer)\n",
    "\n",
    "example_dataloader = DataLoader(\n",
    "    example_dataset,\n",
    "    batch_size=2,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.keys: dict_keys(['prompt', 'chosen', 'rejected', 'rejected_mask', 'chosen_mask'])\n"
     ]
    }
   ],
   "source": [
    "for batch in example_dataloader:\n",
    "    break\n",
    "\n",
    "print(\"batch.keys:\", batch.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
       "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
       "         21017, 46486,    25,   198,    36,  2100,  4985,   262,  1708,  9546,\n",
       "           416, 25449,   340,   656,   262, 24993,  1813,    13,   198,   198,\n",
       "         21017, 23412,    25,   198, 19503,   521, 14610,  1545]),\n",
       " tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
       "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
       "         21017, 46486,    25,   198, 18378,   262,  1708,  6827,   329, 23491,\n",
       "            13,   198,   198, 21017, 23412,    25,   198,  1544,   467,   284,\n",
       "           262,  3952,   790,  1110,    13])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"prompt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We don't really need the responses for training; what we need to feed to the model during training are the `\"chosen\"` and `\"rejected\"` entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The  `\"chosen\"` and `\"rejected\"` response entries are padded so that we can stack them as tensors; similar to the prompts, these response texts are encoded into token IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
       "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
       "         21017, 46486,    25,   198,    36,  2100,  4985,   262,  1708,  9546,\n",
       "           416, 25449,   340,   656,   262, 24993,  1813,    13,   198,   198,\n",
       "         21017, 23412,    25,   198, 19503,   521, 14610,  1545,   198,   198,\n",
       "         21017, 18261,    25,   198,   464, 24993,   286,   262,  1813,  9546,\n",
       "           366, 19503,   521,     1,   318, 11491,    11,   262,  3376, 24993,\n",
       "           318,   366,  6726,  1911, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256],\n",
       "        [21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
       "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
       "         21017, 46486,    25,   198, 18378,   262,  1708,  6827,   329, 23491,\n",
       "            13,   198,   198, 21017, 23412,    25,   198,  1544,   467,   284,\n",
       "           262,  3952,   790,  1110,    13,   198,   198, 21017, 18261,    25,\n",
       "           198,  1544,  2925,   284,   262,  3952,   790,  1110,    13, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256]], device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"chosen\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
       "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
       "         21017, 46486,    25,   198,    36,  2100,  4985,   262,  1708,  9546,\n",
       "           416, 25449,   340,   656,   262, 24993,  1813,    13,   198,   198,\n",
       "         21017, 23412,    25,   198, 19503,   521, 14610,  1545,   198,   198,\n",
       "         21017, 18261,    25,   198,   464, 24993,   286,   262,  1813,  9546,\n",
       "           366, 19503,   521,     1,   318,  6228,   503,  2642,    11,   651,\n",
       "           340,  1978,    11,   262,  3376, 24993,   318,   366,  6726,  1911,\n",
       "         50256],\n",
       "        [21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
       "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
       "         21017, 46486,    25,   198, 18378,   262,  1708,  6827,   329, 23491,\n",
       "            13,   198,   198, 21017, 23412,    25,   198,  1544,   467,   284,\n",
       "           262,  3952,   790,  1110,    13,   198,   198, 21017, 18261,    25,\n",
       "           198,  1544,  2925,   284,   262,  8531,  3952,   790,  2060,  1110,\n",
       "            13, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256]], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"rejected\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_tokens_from_batch(token_ids, tokenizer):\n",
    "    ids_in_python_list = token_ids.flatten().tolist()\n",
    "    return tokenizer.decode(ids_in_python_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Evaluate the following phrase by transforming it into the spelling given.\n",
      "\n",
      "### Input:\n",
      "freind --> friend\n"
     ]
    }
   ],
   "source": [
    "text = decode_tokens_from_batch(\n",
    "    token_ids=batch[\"prompt\"][0],  # [0] for the first entry in the batch\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Evaluate the following phrase by transforming it into the spelling given.\n",
      "\n",
      "### Input:\n",
      "freind --> friend\n",
      "\n",
      "### Response:\n",
      "The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Evaluate the following phrase by transforming it into the spelling given.\n",
      "\n",
      "### Input:\n",
      "freind --> friend\n",
      "\n",
      "### Response:\n",
      "The spelling of the given phrase \"freind\" is flat out wrong, get it together, the correct spelling is \"friend\".<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "text_chosen = decode_tokens_from_batch(\n",
    "    token_ids=batch[\"chosen\"][0],\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "print(text_chosen)\n",
    "print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "text_rejected = decode_tokens_from_batch(\n",
    "    token_ids=batch[\"rejected\"][0],\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "print(text_rejected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Don't worry; the `<|endoftext|>` tokens will be ignored in the loss later so that they won't affect the training outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chosen inputs: torch.Size([81])\n",
      "chosen mask:   torch.Size([81])\n"
     ]
    }
   ],
   "source": [
    "print(\"chosen inputs:\", batch[\"chosen\"][0].shape)\n",
    "print(\"chosen mask:  \", batch[\"chosen_mask\"][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
       "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
       "        21017, 46486,    25,   198,    36,  2100,  4985,   262,  1708,  9546,\n",
       "          416, 25449,   340,   656,   262, 24993,  1813,    13,   198,   198,\n",
       "        21017, 23412,    25,   198, 19503,   521, 14610,  1545,   198,   198,\n",
       "        21017, 18261,    25,   198,   464, 24993,   286,   262,  1813,  9546,\n",
       "          366, 19503,   521,     1,   318, 11491,    11,   262,  3376, 24993,\n",
       "          318,   366,  6726,  1911, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256], device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " batch[\"chosen\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True, False, False, False, False, False, False,\n",
       "        False], device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"chosen_mask\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masking the response for the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Response:\n",
      "The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".\n"
     ]
    }
   ],
   "source": [
    "text = decode_tokens_from_batch(\n",
    "    token_ids=batch[\"chosen\"][0][batch[\"chosen_mask\"][0]],\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Response:\n",
      "The spelling of the given phrase \"freind\" is flat out wrong, get it together, the correct spelling is \"friend\".\n"
     ]
    }
   ],
   "source": [
    "text = decode_tokens_from_batch(\n",
    "    token_ids=batch[\"rejected\"][0][batch[\"rejected_mask\"][0]],\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "## 2.4) Creating training, validation, and test set data loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Above, we worked with a small example subsets from the preference dataset for illustration purposes\n",
    "- Let's now create the actual training, validation, and test set data loaders\n",
    "- This process is identical to creating the data loaders in the pretraining and instruction finetuning chapters and thus should be self-explanatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = PreferenceDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = PreferenceDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = PreferenceDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's iterate through the data loader and take a look at the dataset shapes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 94]) torch.Size([8, 94])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 99]) torch.Size([8, 99])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 97]) torch.Size([8, 97])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 84]) torch.Size([8, 84])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 101]) torch.Size([8, 101])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 84]) torch.Size([8, 84])\n",
      "torch.Size([8, 92]) torch.Size([8, 92])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 100]) torch.Size([8, 100])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 92]) torch.Size([8, 92])\n",
      "torch.Size([8, 93]) torch.Size([8, 93])\n",
      "torch.Size([8, 115]) torch.Size([8, 115])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 95]) torch.Size([8, 95])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 94]) torch.Size([8, 94])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 90]) torch.Size([8, 90])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 85]) torch.Size([8, 85])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 84]) torch.Size([8, 84])\n",
      "torch.Size([8, 84]) torch.Size([8, 84])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 93]) torch.Size([8, 93])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 99]) torch.Size([8, 99])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 86]) torch.Size([8, 86])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 97]) torch.Size([8, 97])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 85]) torch.Size([8, 85])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 85]) torch.Size([8, 85])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 92]) torch.Size([8, 92])\n",
      "torch.Size([8, 85]) torch.Size([8, 85])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 93]) torch.Size([8, 93])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 93]) torch.Size([8, 93])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 90]) torch.Size([8, 90])\n",
      "torch.Size([8, 99]) torch.Size([8, 99])\n",
      "torch.Size([8, 104]) torch.Size([8, 104])\n",
      "torch.Size([8, 101]) torch.Size([8, 101])\n",
      "torch.Size([8, 98]) torch.Size([8, 98])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 84]) torch.Size([8, 84])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 85]) torch.Size([8, 85])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for batch in train_loader:\n",
    "    print(\n",
    "        batch[\"chosen\"].shape,\n",
    "        batch[\"rejected\"].shape,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "# 3) Loading a finetuned LLM for DPO alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. LLM alignment steps, such as RLHF or DPO, assume that we already have an instruction-finetuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This section contains minimal code to load the model that was instruction finetuned and saved in chapter 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.ch7_previous_chapters import GPTModel\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_pth = Path(\"ch7-model/gpt2-medium355M-sft.pth\") \n",
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        path_pth,\n",
    "        map_location=torch.device(\"cpu\"),\n",
    "        weights_only=True\n",
    "    )\n",
    ")\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Below is an instruction that describes a task. Write a response\n",
    "that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response\n",
      "that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "### Response:\n",
      "The meal is cooked every day by the chef.\n"
     ]
    }
   ],
   "source": [
    "from scripts.ch7_previous_chapters import (\n",
    "    generate,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(prompt, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256\n",
    ")\n",
    "\n",
    "response = token_ids_to_text(token_ids, tokenizer)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The meal is cooked every day by the chef.\n"
     ]
    }
   ],
   "source": [
    "def extract_response(response_text, input_text):\n",
    "    return response_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    "\n",
    "response = extract_response(response, prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the two LLMs in DPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As mentioned at the beginning of this notebook, DPO works with two LLMs: \n",
    "    - a policy model (the LLM that we want to optimize) \n",
    "    - a reference model (the original model that we keep unchanged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_model = model\n",
    "\n",
    "reference_model = GPTModel(BASE_CONFIG)\n",
    "reference_model.load_state_dict(\n",
    "    torch.load(\n",
    "        path_pth,\n",
    "        map_location=torch.device(\"cpu\"),\n",
    "        weights_only=True\n",
    "    )\n",
    ")\n",
    "reference_model.eval()\n",
    "\n",
    "policy_model.to(device)\n",
    "reference_model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "# 4) Coding the DPO Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/dpo/3.webp?123\" width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- These lines above calculate the difference in log probabilities (logits) for the chosen and rejected samples for both the policy model and the reference model (this is due to $\\log\\left(\\frac{a}{b}\\right) = \\log a - \\log b$):\n",
    "\n",
    "$$\\log \\left( \\frac{\\pi_\\theta (y_w \\mid x)}{\\pi_\\theta (y_l \\mid x)} \\right) \\quad \\text{and} \\quad \\log \\left( \\frac{\\pi_{\\text{ref}}(y_w \\mid x)}{\\pi_{\\text{ref}}(y_l \\mid x)} \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Next, the code `logits = model_logratios - reference_logratios` computes the difference between the model's log ratios and the reference model's log ratios, i.e., \n",
    "\n",
    "$$\\beta \\log \\left( \\frac{\\pi_\\theta (y_w \\mid x)}{\\pi_{\\text{ref}} (y_w \\mid x)} \\right)\n",
    "- \\beta \\log \\left( \\frac{\\pi_\\theta (y_l \\mid x)}{\\pi_{\\text{ref}} (y_l \\mid x)} \\right)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finally, `losses = -F.logsigmoid(beta * logits)`  calculates the loss using the log-sigmoid function; in the original equation, the term inside the expectation is \n",
    "\n",
    "$$\\log \\sigma \\left( \\beta \\log \\left( \\frac{\\pi_\\theta (y_w \\mid x)}{\\pi_{\\text{ref}} (y_w \\mid x)} \\right)\n",
    "- \\beta \\log \\left( \\frac{\\pi_\\theta (y_l \\mid x)}{\\pi_{\\text{ref}} (y_l \\mid x)} \\right) \\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def compute_dpo_loss(\n",
    "      model_chosen_logprobs,\n",
    "      model_rejected_logprobs,\n",
    "      reference_chosen_logprobs,\n",
    "      reference_rejected_logprobs,\n",
    "      beta=0.1,\n",
    "    ):\n",
    "    \"\"\"Compute the DPO loss for a batch of policy and reference model log probabilities.\n",
    "\n",
    "    Args:\n",
    "        policy_chosen_logprobs: Log probabilities of the policy model for the chosen responses. Shape: (batch_size,)\n",
    "        policy_rejected_logprobs: Log probabilities of the policy model for the rejected responses. Shape: (batch_size,)\n",
    "        reference_chosen_logprobs: Log probabilities of the reference model for the chosen responses. Shape: (batch_size,)\n",
    "        reference_rejected_logprobs: Log probabilities of the reference model for the rejected responses. Shape: (batch_size,)\n",
    "        beta: Temperature parameter for the DPO loss; typically something in the range of 0.1 to 0.5. We ignore the reference model as beta -> 0.\n",
    "        label_smoothing: conservativeness for DPO loss.\n",
    "\n",
    "    Returns:\n",
    "        A tuple of three tensors: (loss, chosen_rewards, rejected_rewards).\n",
    "    \"\"\"\n",
    "\n",
    "    model_logratios = model_chosen_logprobs - model_rejected_logprobs\n",
    "    reference_logratios = reference_chosen_logprobs - reference_rejected_logprobs\n",
    "    logits = model_logratios - reference_logratios\n",
    "\n",
    "    # DPO (Eq. 7 of https://arxiv.org/pdf/2305.18290.pdf)\n",
    "    losses = -F.logsigmoid(beta * logits)\n",
    "\n",
    "    # Optional values to track progress during training\n",
    "    chosen_rewards = (model_chosen_logprobs - reference_chosen_logprobs).detach()\n",
    "    rejected_rewards = (model_rejected_logprobs - reference_rejected_logprobs).detach()\n",
    "\n",
    "    # .mean() to average over the samples in the batch\n",
    "    return losses.mean(), chosen_rewards.mean(), rejected_rewards.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Above, we assumed that the log probabilities were already computed; let's now define a `compute_logprobs` function that we can use to compute these log probabilities that were passed into the `compute_dpo_loss` function above, that is, the values $\\pi_\\theta (y_w \\mid x)$, ${\\pi_\\theta (y_l \\mid x)}$, and so forth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_logprobs(logits, labels, selection_mask=None):\n",
    "    \"\"\"\n",
    "    Compute log probabilities.\n",
    "\n",
    "    Args:\n",
    "      logits: Tensor of shape (batch_size, num_tokens, vocab_size)\n",
    "      labels: Tensor of shape (batch_size, num_tokens)\n",
    "      selection_mask: Tensor for shape (batch_size, num_tokens)\n",
    "\n",
    "    Returns:\n",
    "      mean_log_prob: Mean log probability excluding padding tokens.\n",
    "    \"\"\"\n",
    "\n",
    "    # Labels are the inputs shifted by one\n",
    "    labels = labels[:, 1:].clone()\n",
    "\n",
    "    # Truncate logits to match the labels num_tokens\n",
    "    logits = logits[:, :-1, :]\n",
    "\n",
    "    log_probs = F.log_softmax(logits, dim=-1)\n",
    "\n",
    "    # Gather the log probabilities for the actual labels\n",
    "    selected_log_probs = torch.gather(\n",
    "        input=log_probs,\n",
    "        dim=-1,\n",
    "        index=labels.unsqueeze(-1)\n",
    "    ).squeeze(-1)\n",
    "\n",
    "    if selection_mask is not None:\n",
    "        mask = selection_mask[:, 1:].clone()\n",
    "\n",
    "        # Apply the mask to filter out padding tokens\n",
    "        selected_log_probs = selected_log_probs * mask\n",
    "\n",
    "        # Calculate the average log probability excluding padding tokens\n",
    "        # This averages over the tokens, so the shape is (batch_size, num_tokens)\n",
    "        avg_log_prob = selected_log_probs.sum(-1) / mask.sum(-1)\n",
    "\n",
    "        return avg_log_prob\n",
    "\n",
    "    else:\n",
    "        return selected_log_probs.mean(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data\n",
    "logits = torch.tensor(\n",
    "    [[2.0, 1.0, 0.1],\n",
    "     [0.5, 2.5, 0.3]])  # Shape: (2, 3)\n",
    "targets = torch.tensor([0, 2])  # Shape: (2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual loss using torch.gather\n",
    "log_softmax_logits = F.log_softmax(logits, dim=1)  # Shape: (2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4170, -1.4170, -2.3170],\n",
       "        [-2.2200, -0.2200, -2.4200]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_log_probs = torch.gather(\n",
    "    input=log_softmax_logits,\n",
    "    dim=1,\n",
    "    index=targets.unsqueeze(1), # Shape 2, 1\n",
    ").squeeze(1)  # Shape: (2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4170, -2.4200])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [2]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have taken for the first example in the first batch the first logit of the first token (pos. 0 as stated by the first `targets`value which is `-0.417`).\n",
    "- We have takend for the second example in the batch the logit  in index `2` (pos. 2 as stated by the second `targets`values which is `-2.42`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_loss = -selected_log_probs.mean()  # Averaging over the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4185)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch loss\n",
    "cross_entropy_loss = F.cross_entropy(logits, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4185)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor(\n",
    "  [[1., 2.,],\n",
    "   [3., 4.]]\n",
    ")\n",
    "\n",
    "m = torch.tensor(\n",
    "  [[1, 1],\n",
    "   [0, 1]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Above, `t` is a tensor we want to select from, and `m` is a mask to specify how we want to select\n",
    " - For instance, since `m` contains `[1, 1]` n the first row, it will select two times the value of `t` in index position `1`, which is the value 2.\n",
    " - The second row of `m`, `[0, 1]`, selects index positions 0 and 1 in the second row or `t`, which are `3.` and `4.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.gather(input=t, dim=-1, index=m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final DPO Loss computation at Batch level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The `selection_mask` we use there is to optionally ignore prompt and padding tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dpo_loss_batch(batch, policy_model, reference_model, beta):\n",
    "    \"\"\"Compute the DPO loss on an input batch\"\"\"\n",
    "\n",
    "    # where policy_model(batch[\"chosen\"]) are the logits\n",
    "    policy_chosen_log_probas = compute_logprobs(\n",
    "        logits=policy_model(batch[\"chosen\"]),\n",
    "        labels=batch[\"chosen\"],\n",
    "        selection_mask=batch[\"chosen_mask\"]\n",
    "    )\n",
    "    policy_rejected_log_probas = compute_logprobs(\n",
    "        logits=policy_model(batch[\"rejected\"]),\n",
    "        labels=batch[\"rejected\"],\n",
    "        selection_mask=batch[\"rejected_mask\"]\n",
    "    )\n",
    "    ref_chosen_log_probas = compute_logprobs(\n",
    "        logits=reference_model(batch[\"chosen\"]),\n",
    "        labels=batch[\"chosen\"],\n",
    "        selection_mask=batch[\"chosen_mask\"]\n",
    "    )\n",
    "    ref_rejected_log_probas = compute_logprobs(\n",
    "        logits=reference_model(batch[\"rejected\"]),\n",
    "        labels=batch[\"rejected\"],\n",
    "        selection_mask=batch[\"rejected_mask\"]\n",
    "    )\n",
    "    loss, chosen_rewards, rejected_rewards = compute_dpo_loss(\n",
    "        model_chosen_logprobs=policy_chosen_log_probas,\n",
    "        model_rejected_logprobs=policy_rejected_log_probas,\n",
    "        reference_chosen_logprobs=ref_chosen_log_probas,\n",
    "        reference_rejected_logprobs=ref_rejected_log_probas,\n",
    "        beta=beta\n",
    "    )\n",
    "    return loss, chosen_rewards, rejected_rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BREAKING DOWN THE DPO LOSS BATCH\n",
    "\n",
    "#### a. Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "dataset = PreferenceDataset(example_data, tokenizer)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=2,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: <class 'list'> (len: 2) of torch.Size([48])\n",
      "chosen: <class 'torch.Tensor'> of torch.Size([2, 81])\n",
      "rejected: <class 'torch.Tensor'> of torch.Size([2, 81])\n",
      "rejected_mask: <class 'torch.Tensor'> of torch.Size([2, 81])\n",
      "chosen_mask: <class 'torch.Tensor'> of torch.Size([2, 81])\n"
     ]
    }
   ],
   "source": [
    "for key in batch.keys():\n",
    "    # Get the type\n",
    "    value = batch[key]\n",
    "    value_type = type(value)\n",
    "\n",
    "    # If a list of tensors, get the shape of the first tensor\n",
    "    if isinstance(value, list):\n",
    "        len_list = len(value)\n",
    "        value_shape = value[0].shape\n",
    "        print(f\"{key}: {value_type} (len: {len_list}) of {value_shape}\")\n",
    "    else:\n",
    "        value_shape = value.shape\n",
    "        print(f\"{key}: {value_type} of {value_shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
       "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
       "         21017, 46486,    25,   198,    36,  2100,  4985,   262,  1708,  9546,\n",
       "           416, 25449,   340,   656,   262, 24993,  1813,    13,   198,   198,\n",
       "         21017, 23412,    25,   198, 19503,   521, 14610,  1545,   198,   198,\n",
       "         21017, 18261,    25,   198,   464, 24993,   286,   262,  1813,  9546,\n",
       "           366, 19503,   521,     1,   318, 11491,    11,   262,  3376, 24993,\n",
       "           318,   366,  6726,  1911, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256],\n",
       "        [21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
       "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
       "         21017, 46486,    25,   198, 18378,   262,  1708,  6827,   329, 23491,\n",
       "            13,   198,   198, 21017, 23412,    25,   198,  1544,   467,   284,\n",
       "           262,  3952,   790,  1110,    13,   198,   198, 21017, 18261,    25,\n",
       "           198,  1544,  2925,   284,   262,  3952,   790,  1110,    13, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256]], device='cuda:0')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"chosen\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Forward to get logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = policy_model(batch[\"chosen\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here in the logits we have the logit (not yet prob) for each token, we need the `labels` to specify which is the token in this logits last dimension that corresponds to the actual output token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 81, 50257])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
       "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
       "         21017, 46486,    25,   198,    36,  2100,  4985,   262,  1708,  9546,\n",
       "           416, 25449,   340,   656,   262, 24993,  1813,    13,   198,   198,\n",
       "         21017, 23412,    25,   198, 19503,   521, 14610,  1545,   198,   198,\n",
       "         21017, 18261,    25,   198,   464, 24993,   286,   262,  1813,  9546,\n",
       "           366, 19503,   521,     1,   318, 11491,    11,   262,  3376, 24993,\n",
       "           318,   366,  6726,  1911, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256],\n",
       "        [21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
       "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
       "         21017, 46486,    25,   198, 18378,   262,  1708,  6827,   329, 23491,\n",
       "            13,   198,   198, 21017, 23412,    25,   198,  1544,   467,   284,\n",
       "           262,  3952,   790,  1110,    13,   198,   198, 21017, 18261,    25,\n",
       "           198,  1544,  2925,   284,   262,  3952,   790,  1110,    13, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256]], device='cuda:0')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = batch[\"chosen\"]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 81])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True, False, False, False, False, False, False,\n",
       "         False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False]], device='cuda:0')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection_mask = batch[\"chosen_mask\"]\n",
    "selection_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's simulate what happens inside the `compute_logprobs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([21106,   318,   281, 12064], device='cuda:0')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels are the inputs shifted by one\n",
    "labels = labels[:, 1:].clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  318,   281, 12064,   326], device='cuda:0')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 80])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the dimensions don't match because of the shifting we need to also truncate the logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 81, 50257])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncate logits to match the labels num_tokens\n",
    "logits = logits[:, :-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 80, 50257])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Compute logprobs of the label tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we normalize the logits into a probability in the last dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs = F.log_softmax(logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 80, 50257])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we select accordin to the shifted labels the position of the token in the vocabulary size of the `log_probs` of the token that was actually the next token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 80])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we align the dimensions of `labels` and `log_probs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 80, 1])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.unsqueeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 80, 50257])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d. Token selection based on the next token in the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather the log probabilities for the actual labels\n",
    "selected_log_probs = torch.gather(\n",
    "    input=log_probs,\n",
    "    dim=-1, # or dim = 2\n",
    "    index=labels.unsqueeze(-1)\n",
    ").squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  318,   281, 12064], device='cuda:0')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the specific values of the log probs of each token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0002, device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs[0, 0, 318]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0004, device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs[0, 1, 281]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(    -0.0000, device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs[0, 2, 12064]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They coincide with the selected ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    -0.0002,     -0.0004,     -0.0000], device='cuda:0',\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_log_probs[0, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 80])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_log_probs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e. Masking to only count the loss to the response tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mask**: we also shift the selection mask to match the size of the `selected_log_probs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = selection_mask[:, 1:].clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True, False, False, False, False, False, False,\n",
       "         False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False]], device='cuda:0')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the mask to filter out padding tokens\n",
    "selected_log_probs = selected_log_probs * mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    -0.0000,     -0.0000,     -0.0000,     -0.0000,     -0.0000,\n",
       "            -0.0000,     -0.0000,     -0.0000,     -0.0000,     -0.0000,\n",
       "            -0.0000,     -0.0000,     -0.0000,     -0.0000,     -0.0000,\n",
       "            -0.0000,     -0.0000,     -0.0000,      0.0000,     -0.0000,\n",
       "            -0.0000,     -0.0000,     -0.0000,     -0.0000,     -0.0000,\n",
       "            -0.0000,     -0.0000,     -0.0000,     -0.0000,     -0.0000,\n",
       "            -0.0000,     -0.0000,     -0.0000,     -0.0000,     -0.0000,\n",
       "            -0.0000,     -0.0000,     -0.0000,      0.0000,     -0.0000,\n",
       "            -0.0000,     -0.0000,     -0.0000,     -0.0000,     -0.0000,\n",
       "            -0.0000,     -0.0000,     -0.0000,     -0.0000,     -0.0001,\n",
       "            -0.0004,     -0.0001,     -0.0003,     -0.1191,     -0.0229,\n",
       "            -0.4392,     -0.3107,     -0.0222,     -0.1507,     -1.3676,\n",
       "            -0.0899,     -0.0003,     -0.0127,     -0.2059,     -0.9238,\n",
       "            -1.7289,     -0.2144,     -0.8769,     -0.0009,     -0.0479,\n",
       "            -0.0053,     -0.0256,     -0.3379,     -0.0000,     -0.0000,\n",
       "            -0.0000,     -0.0000,     -0.0000,     -0.0000,     -0.0000],\n",
       "       device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_log_probs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A log_prob closer to 0 corresponds to a higher probability (closer to 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 80])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_log_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_log_prob = selected_log_probs.sum(-1) / mask.sum(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f. Averaging in the same response all the losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have one average log prob of the selected token for each example in the batch.\n",
    "Basically we have averaged over all the selected tokens the `log_prob`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2876, -0.0103], device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_log_prob.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ends the computation of the `compute_logprobs`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_logprobs(logits, labels, selection_mask=None):\n",
    "    \"\"\"\n",
    "    Compute log probabilities.\n",
    "\n",
    "    Args:\n",
    "      logits: Tensor of shape (batch_size, num_tokens, vocab_size)\n",
    "      labels: Tensor of shape (batch_size, num_tokens)\n",
    "      selection_mask: Tensor for shape (batch_size, num_tokens)\n",
    "\n",
    "    Returns:\n",
    "      mean_log_prob: Mean log probability excluding padding tokens.\n",
    "    \"\"\"\n",
    "\n",
    "    # Labels are the inputs shifted by one\n",
    "    labels = labels[:, 1:].clone()\n",
    "\n",
    "    # Truncate logits to match the labels num_tokens\n",
    "    logits = logits[:, :-1, :]\n",
    "\n",
    "    log_probs = F.log_softmax(logits, dim=-1)\n",
    "\n",
    "    # Gather the log probabilities for the actual labels\n",
    "    selected_log_probs = torch.gather(\n",
    "        input=log_probs,\n",
    "        dim=-1,\n",
    "        index=labels.unsqueeze(-1)\n",
    "    ).squeeze(-1)\n",
    "\n",
    "    if selection_mask is not None:\n",
    "        mask = selection_mask[:, 1:].clone()\n",
    "\n",
    "        # Apply the mask to filter out padding tokens\n",
    "        selected_log_probs = selected_log_probs * mask\n",
    "\n",
    "        # Calculate the average log probability excluding padding tokens\n",
    "        # This averages over the tokens, so the shape is (batch_size, num_tokens)\n",
    "        avg_log_prob = selected_log_probs.sum(-1) / mask.sum(-1)\n",
    "\n",
    "        return avg_log_prob\n",
    "\n",
    "    else:\n",
    "        return selected_log_probs.mean(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute_dpo_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compute the log probas for both the `policy` model and the `reference` model for both the `accepted` and the `rejected` responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where policy_model(batch[\"chosen\"]) are the logits\n",
    "policy_chosen_log_probas = compute_logprobs(\n",
    "    logits=policy_model(batch[\"chosen\"]),\n",
    "    labels=batch[\"chosen\"],\n",
    "    selection_mask=batch[\"chosen_mask\"]\n",
    ")\n",
    "policy_rejected_log_probas = compute_logprobs(\n",
    "    logits=policy_model(batch[\"rejected\"]),\n",
    "    labels=batch[\"rejected\"],\n",
    "    selection_mask=batch[\"rejected_mask\"]\n",
    ")\n",
    "ref_chosen_log_probas = compute_logprobs(\n",
    "    logits=reference_model(batch[\"chosen\"]),\n",
    "    labels=batch[\"chosen\"],\n",
    "    selection_mask=batch[\"chosen_mask\"]\n",
    ")\n",
    "ref_rejected_log_probas = compute_logprobs(\n",
    "    logits=reference_model(batch[\"rejected\"]),\n",
    "    labels=batch[\"rejected\"],\n",
    "    selection_mask=batch[\"rejected_mask\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_chosen_log_probas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_rejected_log_probas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_chosen_logprobs = policy_chosen_log_probas\n",
    "model_rejected_logprobs = policy_rejected_log_probas\n",
    "reference_chosen_logprobs = ref_chosen_log_probas\n",
    "reference_rejected_logprobs = ref_rejected_log_probas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the DPO formula, we can convert the ratios of the logs into a single summation and subtraction of the log probabilities of the logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logratios = model_chosen_logprobs - model_rejected_logprobs\n",
    "reference_logratios = reference_chosen_logprobs - reference_rejected_logprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.7940, 2.2816], device='cuda:0', grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_logratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.7940, 2.2816], device='cuda:0', grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_logratios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before applying the `logsigmoid` and the `beta` scaling, we subtract both terms (since we have a total of 4 termins, we have grouped the subtractions 2x2, and now we do the final difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model_logratios - reference_logratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta=0.1\n",
    "losses = -F.logsigmoid(beta * logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6931, 0.6931], device='cuda:0', grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calibrate how different the model with the current policy logprobs are from the reference model with this calculations (no needed for anything, just monitoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional values to track progress during training\n",
    "chosen_rewards = (model_chosen_logprobs - reference_chosen_logprobs).detach()\n",
    "rejected_rewards = (model_rejected_logprobs - reference_rejected_logprobs).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0.], device='cuda:0')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0.], device='cuda:0')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rejected_rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The return of the function is simply the **average over the batch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.6931, device='cuda:0', grad_fn=<MeanBackward0>),\n",
       " tensor(0., device='cuda:0'),\n",
       " tensor(0., device='cuda:0'))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses.mean(), chosen_rewards.mean(), rejected_rewards.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dpo_loss_batch(batch, policy_model, reference_model, beta):\n",
    "    \"\"\"Compute the DPO loss on an input batch\"\"\"\n",
    "\n",
    "    # where policy_model(batch[\"chosen\"]) are the logits\n",
    "    policy_chosen_log_probas = compute_logprobs(\n",
    "        logits=policy_model(batch[\"chosen\"]),\n",
    "        labels=batch[\"chosen\"],\n",
    "        selection_mask=batch[\"chosen_mask\"]\n",
    "    )\n",
    "    policy_rejected_log_probas = compute_logprobs(\n",
    "        logits=policy_model(batch[\"rejected\"]),\n",
    "        labels=batch[\"rejected\"],\n",
    "        selection_mask=batch[\"rejected_mask\"]\n",
    "    )\n",
    "    ref_chosen_log_probas = compute_logprobs(\n",
    "        logits=reference_model(batch[\"chosen\"]),\n",
    "        labels=batch[\"chosen\"],\n",
    "        selection_mask=batch[\"chosen_mask\"]\n",
    "    )\n",
    "    ref_rejected_log_probas = compute_logprobs(\n",
    "        logits=reference_model(batch[\"rejected\"]),\n",
    "        labels=batch[\"rejected\"],\n",
    "        selection_mask=batch[\"rejected_mask\"]\n",
    "    )\n",
    "    loss, chosen_rewards, rejected_rewards = compute_dpo_loss(\n",
    "        model_chosen_logprobs=policy_chosen_log_probas,\n",
    "        model_rejected_logprobs=policy_rejected_log_probas,\n",
    "        reference_chosen_logprobs=ref_chosen_log_probas,\n",
    "        reference_rejected_logprobs=ref_rejected_log_probas,\n",
    "        beta=beta\n",
    "    )\n",
    "    return loss, chosen_rewards, rejected_rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for a single batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(0.6931, device='cuda:0'), tensor(0., device='cuda:0'), tensor(0., device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    loss_tup = compute_dpo_loss_batch(batch, policy_model, reference_model, beta=0.1)\n",
    "print(loss_tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, chosen_rewards, rejected_rewards = loss_tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6931471824645996"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we set the models to track gradients we can compute the loss.backward, this will be done in our training function `train_model_dpo_simple`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DPO Loss for each DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dpo_loss_loader(data_loader, policy_model, reference_model, beta, num_batches=None):\n",
    "    \"\"\"Apply compute_dpo_loss_batch to a whole data loader\"\"\"\n",
    "\n",
    "    total_loss, total_chosen_rewards, total_rejected_rewards = 0., 0., 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss, chosen_rewards, rejected_rewards = compute_dpo_loss_batch(\n",
    "                batch=batch,\n",
    "                policy_model=policy_model,\n",
    "                reference_model=reference_model,\n",
    "                beta=beta\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "            total_chosen_rewards += chosen_rewards.item()\n",
    "            total_rejected_rewards += rejected_rewards.item()\n",
    "\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # calculate average\n",
    "    total_loss /= num_batches\n",
    "    total_chosen_rewards /= num_batches\n",
    "    total_rejected_rewards /= num_batches\n",
    "    return total_loss, total_chosen_rewards, total_rejected_rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Why a specified `num_batches`? That's purely for efficiency reasons (because calculating the loss on the whole dataset each time would slow down the training significantly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing DPO Loss for All the Train / Valid sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_dpo_loss_loader(policy_model, reference_model, train_loader, val_loader, beta, eval_iter):\n",
    "    \"\"\"Compute the DPO loss for the training and validation dataset\"\"\"\n",
    "\n",
    "    policy_model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss, train_chosen_rewards, train_rejected_rewards = compute_dpo_loss_loader(\n",
    "            data_loader=train_loader,\n",
    "            policy_model=policy_model,\n",
    "            reference_model=reference_model,\n",
    "            beta=beta,\n",
    "            num_batches=eval_iter\n",
    "        )\n",
    "\n",
    "        val_loss, val_chosen_rewards, val_rejected_rewards = compute_dpo_loss_loader(\n",
    "            data_loader=val_loader,\n",
    "            policy_model=policy_model,\n",
    "            reference_model=reference_model,\n",
    "            beta=beta,\n",
    "            num_batches=eval_iter\n",
    "        )\n",
    "\n",
    "    res = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_chosen_reward\": train_chosen_rewards,\n",
    "        \"train_rejected_reward\": train_rejected_rewards,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_chosen_reward\": val_chosen_rewards,\n",
    "        \"val_rejected_reward\": val_rejected_rewards\n",
    "    }\n",
    "\n",
    "    policy_model.train()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "# 5) Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - we swap the cross-entropy loss with our new DPO loss function\n",
    " - we also track the rewards and reward margins, which are commonly used in RLHF and DPO contexts to track the training progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.ch7_previous_chapters import generate_and_print_sample\n",
    "\n",
    "\n",
    "def train_model_dpo_simple(\n",
    "    policy_model, reference_model, train_loader, val_loader,\n",
    "    optimizer, num_epochs, beta,\n",
    "    eval_freq, eval_iter, start_context, tokenizer\n",
    "):\n",
    "\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    tracking = {\n",
    "        \"train_losses\": [],\n",
    "        \"train_chosen_rewards\": [],\n",
    "        \"train_rejected_rewards\": [],\n",
    "        \"val_losses\": [],\n",
    "        \"val_chosen_rewards\": [],\n",
    "        \"val_rejected_rewards\": [],\n",
    "        \"tokens_seen\": []\n",
    "    }\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        policy_model.train()  # Set model to training mode\n",
    "\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "\n",
    "            optimizer.zero_grad()  # Reset loss gradients from previous batch iteration\n",
    "\n",
    "            loss, chosen_rewards, rejected_rewards = compute_dpo_loss_batch(\n",
    "                batch=batch,\n",
    "                policy_model=policy_model,\n",
    "                reference_model=reference_model,\n",
    "                beta=beta\n",
    "            )\n",
    "\n",
    "            loss.backward()  # Calculate loss gradients\n",
    "            optimizer.step()  # Update model weights using loss gradients\n",
    "\n",
    "            tokens_seen += batch[\"chosen\"].numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                res = evaluate_dpo_loss_loader(\n",
    "                    policy_model=policy_model,\n",
    "                    reference_model=reference_model,\n",
    "                    train_loader=train_loader,\n",
    "                    val_loader=val_loader,\n",
    "                    beta=beta,\n",
    "                    eval_iter=eval_iter\n",
    "                )\n",
    "                tracking[\"train_losses\"].append(res[\"train_loss\"])\n",
    "                tracking[\"train_chosen_rewards\"].append(res[\"train_chosen_reward\"])\n",
    "                tracking[\"train_rejected_rewards\"].append(res[\"train_rejected_reward\"])\n",
    "                tracking[\"val_losses\"].append(res[\"val_loss\"])\n",
    "                tracking[\"val_chosen_rewards\"].append(res[\"val_chosen_reward\"])\n",
    "                tracking[\"val_rejected_rewards\"].append(res[\"val_rejected_reward\"])\n",
    "                tracking[\"tokens_seen\"].append(tokens_seen)\n",
    "                train_reward_margin = res[\"train_chosen_reward\"] - res[\"train_rejected_reward\"]\n",
    "                val_reward_margin = res[\"val_chosen_reward\"] - res[\"val_rejected_reward\"]\n",
    "\n",
    "                print(\n",
    "                    f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                    f\"Train loss {res['train_loss']:.3f}, Val loss {res['val_loss']:.3f}, \"\n",
    "                    f\"Train reward margins {train_reward_margin:.3f}, \"\n",
    "                    f\"Val reward margins {val_reward_margin:.3f}\"\n",
    "                )\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            device=loss.device,\n",
    "            start_context=start_context\n",
    "        )\n",
    "\n",
    "    return tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Before we start the training, let's print the initial losses and rewards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6931471824645996\n",
      "Validation loss: 0.6931471824645996\n",
      "Train reward margin: 0.0\n",
      "Val reward margin: 0.0\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n",
    "\n",
    "res = evaluate_dpo_loss_loader(\n",
    "    policy_model=policy_model,\n",
    "    reference_model=reference_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    beta=0.1,\n",
    "    eval_iter=5\n",
    ")\n",
    "\n",
    "print(\"Training loss:\", res[\"train_loss\"])\n",
    "print(\"Validation loss:\", res[\"val_loss\"])\n",
    "\n",
    "print(\"Train reward margin:\", res[\"train_chosen_reward\"] - res[\"train_rejected_reward\"])\n",
    "print(\"Val reward margin:\", res[\"val_chosen_reward\"] - res[\"val_rejected_reward\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Also, let's take a look at some of the initial model responses (the first 3 examples in the validation set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "Correct response:\n",
      ">> The meal is cooked by the chef every day.\n",
      "\n",
      "Model response:\n",
      ">> The meal is cooked every day by the chef.\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Classify an input string as either a noun or a verb.\n",
      "\n",
      "### Input:\n",
      "Dance\n",
      "\n",
      "Correct response:\n",
      ">> 'Dance' can be classified as a verb.\n",
      "\n",
      "Model response:\n",
      ">> Dance is a verb.\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a metaphor.\n",
      "\n",
      "### Input:\n",
      "The book is very interesting.\n",
      "\n",
      "Correct response:\n",
      ">> The book is a page-turner.\n",
      "\n",
      "Model response:\n",
      ">> The book is like a novel.\n",
      "\n",
      "-------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "\n",
    "for entry in val_data[:3]:\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    ")\n",
    "\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"\\n-------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - we are only passing the parameters of the policy model into the `AdamW` optimizer; that's the model we want to optimize (we don't want to modify the reference model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - we only train for 1 epoch; that's because **DPO is very prone to collapse** (the loss might improve, but the model will start generating nonsensical texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- in DPO, it's best to use a very **small learning rate**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - the beta value can be increased from 0.1 to 0.5 to reduce the effect of DPO (we use 0.1 here to make the results more noticeable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 4\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = PreferenceDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = PreferenceDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = PreferenceDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 0.206, Val loss 0.362, Train reward margins 19.553, Val reward margins 12.611\n",
      "Ep 1 (Step 000005): Train loss 0.254, Val loss 0.357, Train reward margins 17.514, Val reward margins 12.662\n",
      "Ep 1 (Step 000010): Train loss 0.228, Val loss 0.356, Train reward margins 19.201, Val reward margins 12.255\n",
      "Ep 1 (Step 000015): Train loss 0.164, Val loss 0.350, Train reward margins 22.289, Val reward margins 12.361\n",
      "Ep 1 (Step 000020): Train loss 0.219, Val loss 0.342, Train reward margins 20.364, Val reward margins 12.306\n",
      "Ep 1 (Step 000025): Train loss 0.191, Val loss 0.340, Train reward margins 21.540, Val reward margins 11.950\n",
      "Ep 1 (Step 000030): Train loss 0.268, Val loss 0.339, Train reward margins 15.755, Val reward margins 11.916\n",
      "Ep 1 (Step 000035): Train loss 0.231, Val loss 0.337, Train reward margins 18.686, Val reward margins 12.006\n",
      "Ep 1 (Step 000040): Train loss 0.227, Val loss 0.333, Train reward margins 19.943, Val reward margins 12.210\n",
      "Ep 1 (Step 000045): Train loss 0.141, Val loss 0.323, Train reward margins 24.176, Val reward margins 12.855\n",
      "Ep 1 (Step 000050): Train loss 0.206, Val loss 0.321, Train reward margins 19.761, Val reward margins 12.750\n",
      "Ep 1 (Step 000055): Train loss 0.178, Val loss 0.325, Train reward margins 22.480, Val reward margins 12.069\n",
      "Ep 1 (Step 000060): Train loss 0.183, Val loss 0.320, Train reward margins 19.686, Val reward margins 12.414\n",
      "Ep 1 (Step 000065): Train loss 0.201, Val loss 0.311, Train reward margins 20.830, Val reward margins 13.688\n",
      "Ep 1 (Step 000070): Train loss 0.171, Val loss 0.313, Train reward margins 21.003, Val reward margins 14.291\n",
      "Ep 1 (Step 000075): Train loss 0.200, Val loss 0.315, Train reward margins 20.501, Val reward margins 14.489\n",
      "Ep 1 (Step 000080): Train loss 0.133, Val loss 0.314, Train reward margins 23.819, Val reward margins 14.362\n",
      "Ep 1 (Step 000085): Train loss 0.121, Val loss 0.312, Train reward margins 29.419, Val reward margins 13.718\n",
      "Ep 1 (Step 000090): Train loss 0.178, Val loss 0.313, Train reward margins 19.223, Val reward margins 13.125\n",
      "Ep 1 (Step 000095): Train loss 0.179, Val loss 0.316, Train reward margins 20.505, Val reward margins 12.827\n",
      "Ep 1 (Step 000100): Train loss 0.224, Val loss 0.319, Train reward margins 21.821, Val reward margins 12.653\n",
      "Ep 1 (Step 000105): Train loss 0.117, Val loss 0.325, Train reward margins 25.132, Val reward margins 12.311\n",
      "Ep 1 (Step 000110): Train loss 0.157, Val loss 0.321, Train reward margins 22.107, Val reward margins 12.706\n",
      "Ep 1 (Step 000115): Train loss 0.136, Val loss 0.316, Train reward margins 26.571, Val reward margins 13.276\n",
      "Ep 1 (Step 000120): Train loss 0.128, Val loss 0.314, Train reward margins 25.206, Val reward margins 13.843\n",
      "Ep 1 (Step 000125): Train loss 0.153, Val loss 0.312, Train reward margins 21.828, Val reward margins 14.080\n",
      "Ep 1 (Step 000130): Train loss 0.135, Val loss 0.311, Train reward margins 24.297, Val reward margins 14.057\n",
      "Ep 1 (Step 000135): Train loss 0.166, Val loss 0.313, Train reward margins 20.649, Val reward margins 13.775\n",
      "Ep 1 (Step 000140): Train loss 0.094, Val loss 0.317, Train reward margins 26.839, Val reward margins 13.616\n",
      "Ep 1 (Step 000145): Train loss 0.132, Val loss 0.322, Train reward margins 25.235, Val reward margins 13.229\n",
      "Ep 1 (Step 000150): Train loss 0.160, Val loss 0.325, Train reward margins 22.363, Val reward margins 12.902\n",
      "Ep 1 (Step 000155): Train loss 0.167, Val loss 0.324, Train reward margins 23.829, Val reward margins 13.144\n",
      "Ep 1 (Step 000160): Train loss 0.160, Val loss 0.321, Train reward margins 22.909, Val reward margins 13.929\n",
      "Ep 1 (Step 000165): Train loss 0.196, Val loss 0.322, Train reward margins 22.481, Val reward margins 14.477\n",
      "Ep 1 (Step 000170): Train loss 0.187, Val loss 0.324, Train reward margins 21.934, Val reward margins 14.420\n",
      "Ep 1 (Step 000175): Train loss 0.157, Val loss 0.323, Train reward margins 22.035, Val reward margins 13.799\n",
      "Ep 1 (Step 000180): Train loss 0.147, Val loss 0.324, Train reward margins 25.865, Val reward margins 13.211\n",
      "Ep 1 (Step 000185): Train loss 0.087, Val loss 0.324, Train reward margins 28.138, Val reward margins 12.948\n",
      "Ep 1 (Step 000190): Train loss 0.156, Val loss 0.327, Train reward margins 24.059, Val reward margins 12.727\n",
      "Ep 1 (Step 000195): Train loss 0.165, Val loss 0.327, Train reward margins 27.243, Val reward margins 12.804\n",
      "Ep 1 (Step 000200): Train loss 0.138, Val loss 0.321, Train reward margins 27.902, Val reward margins 13.201\n",
      "Ep 1 (Step 000205): Train loss 0.095, Val loss 0.315, Train reward margins 29.792, Val reward margins 13.857\n",
      "Ep 1 (Step 000210): Train loss 0.222, Val loss 0.311, Train reward margins 22.094, Val reward margins 14.332\n",
      "Ep 1 (Step 000215): Train loss 0.099, Val loss 0.311, Train reward margins 27.033, Val reward margins 14.532\n",
      "Ep 1 (Step 000220): Train loss 0.139, Val loss 0.310, Train reward margins 23.789, Val reward margins 14.604\n",
      "Ep 1 (Step 000225): Train loss 0.133, Val loss 0.312, Train reward margins 24.353, Val reward margins 14.198\n",
      "Ep 1 (Step 000230): Train loss 0.092, Val loss 0.312, Train reward margins 29.588, Val reward margins 14.522\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Rewrite the sentence using a metaphor.  ### Input: The book is very interesting.<|endoftext|>The following is an instruction that describes a task.  Please provide a suitable response.<|endoftext|>The following is an instruction that describes a task.  Please provide a suitable response.<|endoftext|>The following phrase could be used to describe a large number\n",
      "Training completed in 1.13 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(policy_model.parameters(), lr=5e-6, weight_decay=0.01)\n",
    "\n",
    "num_epochs = 1\n",
    "tracking = train_model_dpo_simple(\n",
    "    policy_model=policy_model,\n",
    "    reference_model=reference_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=num_epochs,\n",
    "    beta=0.1, # value between 0.1 and 0.5\n",
    "    eval_freq=5,\n",
    "    eval_iter=5,\n",
    "    start_context=format_input(val_data[2]),\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About the memory consumption of an object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy model occupies approximately 3195.72 MB of GPU memory (static, excluding activations and optimizer state).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def get_model_training_memory(model):\n",
    "    # Ensure the model is on GPU\n",
    "    if next(model.parameters()).device.type != 'cuda':\n",
    "        raise ValueError(\"Model is not on GPU.\")\n",
    "    \n",
    "    # Memory for parameters\n",
    "    param_memory = sum(param.nelement() * param.element_size() for param in model.parameters())\n",
    "    \n",
    "    # Memory for gradients (same size as parameters)\n",
    "    gradient_memory = param_memory  # Gradients are the same size as parameters\n",
    "    \n",
    "    # Memory for buffers\n",
    "    buffer_memory = sum(buffer.nelement() * buffer.element_size() for buffer in model.buffers())\n",
    "    \n",
    "    # Total static memory\n",
    "    static_memory = param_memory + gradient_memory + buffer_memory\n",
    "    \n",
    "    return static_memory\n",
    "\n",
    "# Assuming policy_model is already on GPU\n",
    "static_memory_in_bytes = get_model_training_memory(policy_model)\n",
    "static_memory_in_megabytes = static_memory_in_bytes / (1024 ** 2)\n",
    "\n",
    "print(f\"Policy model occupies approximately {static_memory_in_megabytes:.2f} MB of GPU memory (static, excluding activations and optimizer state).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Analyze the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(tracking[\"train_losses\"]))\n",
    "plot_losses(\n",
    "    epochs_seen=epochs_tensor,\n",
    "    tokens_seen=tracking[\"tokens_seen\"],\n",
    "    train_losses=tracking[\"train_losses\"],\n",
    "    val_losses=tracking[\"val_losses\"],\n",
    "    label=\"loss\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we can see above, the loss continues to improve, which is a good sign\n",
    "- Based on the downward slope, one might be tempted to train the model a bit further (and readers are encouraged to try this), but note that DPO is prone to collapse, where the model may start generating nonsensical responses\n",
    "- Next, let's take a look at the reward margins:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reward Margins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_reward_margins = [i-j for i,j in zip(tracking[\"train_chosen_rewards\"], tracking[\"train_rejected_rewards\"])]\n",
    "val_reward_margins = [i-j for i,j in zip(tracking[\"val_chosen_rewards\"], tracking[\"val_rejected_rewards\"])]\n",
    "\n",
    "plot_losses(\n",
    "    epochs_seen=epochs_tensor,\n",
    "    tokens_seen=tracking[\"tokens_seen\"],\n",
    "    train_losses=train_reward_margins,\n",
    "    val_losses=val_reward_margins,\n",
    "    label=\"loss\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we can see, and as it's desired, the reward margins improve; this mirrors the loss curve and is a good sign\n",
    "- Note that DPO losses and reward margins are valuable metrics to track during training; however, they don't tell the whole story\n",
    "- Lastly, and most importantly, we have to conduct a qualitative check of the responses\n",
    "- Here, we will look at the response (in addition, you could use an LLM to score the responses similar to chapter 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualitative checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "Correct response:\n",
      ">> The meal is cooked by the chef every day.\n",
      "\n",
      "Reference model response:\n",
      ">> The meal is cooked every day by the chef.\n",
      "\n",
      "Policy model response:\n",
      ">> \n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Classify an input string as either a noun or a verb.\n",
      "\n",
      "### Input:\n",
      "Dance\n",
      "\n",
      "Correct response:\n",
      ">> 'Dance' can be classified as a verb.\n",
      "\n",
      "Reference model response:\n",
      ">> Dance is a verb.\n",
      "\n",
      "Policy model response:\n",
      ">> \n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a metaphor.\n",
      "\n",
      "### Input:\n",
      "The book is very interesting.\n",
      "\n",
      "Correct response:\n",
      ">> The book is a page-turner.\n",
      "\n",
      "Reference model response:\n",
      ">> The book is like a novel.\n",
      "\n",
      "Policy model response:\n",
      ">> \n",
      "\n",
      "-------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "\n",
    "for entry in val_data[:3]:\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=reference_model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    reference_response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=policy_model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    policy_response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nReference model response:\\n>> {reference_response_text.strip()}\")\n",
    "    print(f\"\\nPolicy model response:\\n>> {policy_response_text.strip()}\")\n",
    "    print(\"\\n-------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "in1 = text_to_token_ids(input_text, tokenizer).to(device)\n",
    "out1 = policy_model(in1)\n",
    "out1r = reference_model(in1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 44])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 44, 50257])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 44, 50257])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Reference model response:\n",
      ">> The car is as fast as a bullet.\n",
      "\n",
      "Policy model response:\n",
      ">> \n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Reference model response:\n",
      ">> The type of cloud associated with thunderstorms is a cumulus cloud.\n",
      "\n",
      "Policy model response:\n",
      ">> \n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Reference model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "\n",
      "Policy model response:\n",
      ">> \n",
      "\n",
      "-------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=reference_model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    reference_response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=policy_model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    policy_response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nReference model response:\\n>> {reference_response_text.strip()}\")\n",
    "    print(f\"\\nPolicy model response:\\n>> {policy_response_text.strip()}\")\n",
    "    print(\"\\n-------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kr_llmfs",
   "language": "python",
   "name": "kr_llmfs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
